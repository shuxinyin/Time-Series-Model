

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Model Training &mdash; tft-torch 0.0.1 documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "document", "processHtmlClass": "math|output_area"}}</script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="tft-torch Modules" href="../modules.html" />
    <link rel="prev" title="Favorita Dataset Creation Example" href="DataGenerationExample.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> tft-torch
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../introduction.html">tft-torch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../tutorials.html">Tutorials</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="DataGenerationExample.html">Favorita Dataset Creation Example</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Model Training</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Importing-the-required-libraries">Importing the required libraries</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Data-related">Data-related</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#Modeling-configuration">Modeling configuration</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Model-Creation-and-Initiation">Model Creation and Initiation</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Data-Preparation">Data Preparation</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Training-Procedure">Training Procedure</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#Training-Settings">Training Settings</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#Explore-Model-Outputs">Explore Model Outputs</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Apply-the-model">Apply the model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Target-Signal-Trajectory">Target Signal Trajectory</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#Selection-Weights">Selection Weights</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Attention-Scores">Attention Scores</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#One-step-ahead">One step ahead</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Multihorizon-Attention">Multihorizon Attention</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../modules.html">tft-torch Modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../help.html">Help</a></li>
<li class="toctree-l1"><a class="reference internal" href="../authors.html">Authors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../license.html">License</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">tft-torch</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../tutorials.html">Tutorials</a> &raquo;</li>
        
      <li>Model Training</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/tutorials/TrainingExample.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt a.copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="Model-Training">
<h1>Model Training<a class="headerlink" href="#Model-Training" title="Permalink to this headline">¶</a></h1>
<p>This tutorial demonstrates the training of the <code class="docutils literal notranslate"><span class="pre">TemporalFusionTransformer</span></code> model.</p>
<p>The demonstration is using the processed version of <a class="reference external" href="https://www.kaggle.com/c/favorita-grocery-sales-forecasting/overview">Corporación Favorita Grocery Sales Forecasting</a> dataset, as demonstrated in the <strong>Favorita Dataset Creation Example</strong> tutorial, which is also part of this documentation.</p>
<p>The training routine implemented below, uses <em>pure</em> pytorch, for clarity purposes. However, it can be easily adapted to frameworks such as <a class="reference external" href="https://pytorch.org/ignite/index.html">pytorch-ignite</a> or <a class="reference external" href="https://www.pytorchlightning.ai/">pytorch-lightning</a> to facilitate, orchestrate, and automate some of the training procedure.</p>
<p>For a comprehensive explanation of the model and its structure, refer to our <a class="reference external" href="https://www.playtika-blog.com/playtika-ai/multi-horizon-forecasting-using-temporal-fusion-transformers-a-comprehensive-overview-part-1/">blogpost</a>.</p>
<div class="section" id="Importing-the-required-libraries">
<h2>Importing the required libraries<a class="headerlink" href="#Importing-the-required-libraries" title="Permalink to this headline">¶</a></h2>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="o">%</span><span class="k">load_ext</span> autoreload
<span class="o">%</span><span class="k">autoreload</span> 2
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Dict</span><span class="p">,</span><span class="n">List</span><span class="p">,</span><span class="n">Tuple</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">import</span> <span class="nn">copy</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">omegaconf</span> <span class="kn">import</span> <span class="n">OmegaConf</span><span class="p">,</span><span class="n">DictConfig</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">optim</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.init</span> <span class="k">as</span> <span class="nn">init</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">Subset</span>
<span class="kn">from</span> <span class="nn">tft_torch.tft</span> <span class="kn">import</span> <span class="n">TemporalFusionTransformer</span>
<span class="kn">import</span> <span class="nn">tft_torch.loss</span> <span class="k">as</span> <span class="nn">tft_loss</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Data-related">
<h2>Data-related<a class="headerlink" href="#Data-related" title="Permalink to this headline">¶</a></h2>
<p>Setting the path to the location in which we saved the processed dataset in the previous tutorial:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">data_path</span> <span class="o">=</span> <span class="s1">&#39;.../data/favorita/data.pickle&#39;</span>
</pre></div>
</div>
</div>
<p>Reading the pickle we saved, and take a pick at its content:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span><span class="s1">&#39;rb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">fp</span><span class="p">:</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">fp</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="nb">list</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[&#39;data_sets&#39;, &#39;feature_map&#39;, &#39;scalers&#39;, &#39;categorical_cardinalities&#39;]
</pre></div></div>
</div>
<p>Displaying the content of the <code class="docutils literal notranslate"><span class="pre">data_sets</span></code> key. Note that the shapes of the array, in case you follow the previous tutorial, depends on the range of dates configured.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">for</span> <span class="n">set_name</span> <span class="ow">in</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;data_sets&#39;</span><span class="p">]:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;=======&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">set_name</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;=======&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">arr_name</span><span class="p">,</span><span class="n">arr</span> <span class="ow">in</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;data_sets&#39;</span><span class="p">][</span><span class="n">set_name</span><span class="p">]</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">arr_name</span><span class="si">}</span><span class="s2"> (shape,dtype)&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">arr</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">arr</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
=======
train
=======
time_index (shape,dtype)
(11532481,) object
combination_id (shape,dtype)
(11532481,) &lt;U10
static_feats_numeric (shape,dtype)
(11532481, 0) float32
static_feats_categorical (shape,dtype)
(11532481, 9) int32
historical_ts_numeric (shape,dtype)
(11532481, 90, 4) float32
historical_ts_categorical (shape,dtype)
(11532481, 90, 7) int32
future_ts_numeric (shape,dtype)
(11532481, 30, 1) float32
future_ts_categorical (shape,dtype)
(11532481, 30, 7) int32
target (shape,dtype)
(11532481, 30) float32
=======
validation
=======
time_index (shape,dtype)
(120833,) object
combination_id (shape,dtype)
(120833,) &lt;U10
static_feats_numeric (shape,dtype)
(120833, 0) float32
static_feats_categorical (shape,dtype)
(120833, 9) int32
historical_ts_numeric (shape,dtype)
(120833, 90, 4) float32
historical_ts_categorical (shape,dtype)
(120833, 90, 7) int32
future_ts_numeric (shape,dtype)
(120833, 30, 1) float32
future_ts_categorical (shape,dtype)
(120833, 30, 7) int32
target (shape,dtype)
(120833, 30) float32
=======
test
=======
time_index (shape,dtype)
(3454260,) object
combination_id (shape,dtype)
(3454260,) &lt;U10
static_feats_numeric (shape,dtype)
(3454260, 0) float32
static_feats_categorical (shape,dtype)
(3454260, 9) int32
historical_ts_numeric (shape,dtype)
(3454260, 90, 4) float32
historical_ts_categorical (shape,dtype)
(3454260, 90, 7) int32
future_ts_numeric (shape,dtype)
(3454260, 30, 1) float32
future_ts_categorical (shape,dtype)
(3454260, 30, 7) int32
target (shape,dtype)
(3454260, 30) float32
</pre></div></div>
</div>
<div class="section" id="Modeling-configuration">
<h3>Modeling configuration<a class="headerlink" href="#Modeling-configuration" title="Permalink to this headline">¶</a></h3>
<p>We have some arguments to configure, related to the optimization methodology and to the model structure:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">configuration</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;optimization&#39;</span><span class="p">:</span>
                 <span class="p">{</span>
                     <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;training&#39;</span><span class="p">:</span> <span class="mi">256</span><span class="p">,</span> <span class="s1">&#39;inference&#39;</span><span class="p">:</span> <span class="mi">4096</span><span class="p">},</span>
                     <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.001</span><span class="p">,</span>
                     <span class="s1">&#39;max_grad_norm&#39;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>
                 <span class="p">}</span>
                 <span class="p">,</span>
                 <span class="s1">&#39;model&#39;</span><span class="p">:</span>
                 <span class="p">{</span>
                     <span class="s1">&#39;dropout&#39;</span><span class="p">:</span> <span class="mf">0.05</span><span class="p">,</span>
                     <span class="s1">&#39;state_size&#39;</span><span class="p">:</span> <span class="mi">64</span><span class="p">,</span>
                     <span class="s1">&#39;output_quantiles&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">],</span>
                     <span class="s1">&#39;lstm_layers&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
                     <span class="s1">&#39;attention_heads&#39;</span><span class="p">:</span> <span class="mi">4</span>
                 <span class="p">},</span>
                 <span class="c1"># these arguments are related to possible extensions of the model class</span>
                 <span class="s1">&#39;task_type&#39;</span><span class="p">:</span><span class="s1">&#39;regression&#39;</span><span class="p">,</span>
                 <span class="s1">&#39;target_window_start&#39;</span><span class="p">:</span> <span class="kc">None</span>
                <span class="p">}</span>
</pre></div>
</div>
</div>
<p>In addition to the configuration parameters mentioned above, the model also expects the some meta data, specifying the structure of the input, including how many variables compose each input channel, and the cardinalities for the categorical variables (which are required for the embedding layers). The meta data specified above is available as part of the pickle we created when we processed the raw data, so here it comes handy.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">feature_map</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;feature_map&#39;</span><span class="p">]</span>
<span class="n">cardinalities_map</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;categorical_cardinalities&#39;</span><span class="p">]</span>

<span class="n">structure</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;num_historical_numeric&#39;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">feature_map</span><span class="p">[</span><span class="s1">&#39;historical_ts_numeric&#39;</span><span class="p">]),</span>
    <span class="s1">&#39;num_historical_categorical&#39;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">feature_map</span><span class="p">[</span><span class="s1">&#39;historical_ts_categorical&#39;</span><span class="p">]),</span>
    <span class="s1">&#39;num_static_numeric&#39;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">feature_map</span><span class="p">[</span><span class="s1">&#39;static_feats_numeric&#39;</span><span class="p">]),</span>
    <span class="s1">&#39;num_static_categorical&#39;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">feature_map</span><span class="p">[</span><span class="s1">&#39;static_feats_categorical&#39;</span><span class="p">]),</span>
    <span class="s1">&#39;num_future_numeric&#39;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">feature_map</span><span class="p">[</span><span class="s1">&#39;future_ts_numeric&#39;</span><span class="p">]),</span>
    <span class="s1">&#39;num_future_categorical&#39;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">feature_map</span><span class="p">[</span><span class="s1">&#39;future_ts_categorical&#39;</span><span class="p">]),</span>
    <span class="s1">&#39;historical_categorical_cardinalities&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">cardinalities_map</span><span class="p">[</span><span class="n">feat</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">feat</span> <span class="ow">in</span> <span class="n">feature_map</span><span class="p">[</span><span class="s1">&#39;historical_ts_categorical&#39;</span><span class="p">]],</span>
    <span class="s1">&#39;static_categorical_cardinalities&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">cardinalities_map</span><span class="p">[</span><span class="n">feat</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">feat</span> <span class="ow">in</span> <span class="n">feature_map</span><span class="p">[</span><span class="s1">&#39;static_feats_categorical&#39;</span><span class="p">]],</span>
    <span class="s1">&#39;future_categorical_cardinalities&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">cardinalities_map</span><span class="p">[</span><span class="n">feat</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">feat</span> <span class="ow">in</span> <span class="n">feature_map</span><span class="p">[</span><span class="s1">&#39;future_ts_categorical&#39;</span><span class="p">]],</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<p>Note that we add <code class="docutils literal notranslate"><span class="pre">1</span></code> to each of the categorical cardinalities. The reason for that is that the categorical cardinalities are taken from the <code class="docutils literal notranslate"><span class="pre">LabelEncoder</span></code> objects which were used for encoding the data in the processing phase. As these <code class="docutils literal notranslate"><span class="pre">LabelEncoder</span></code> objects were fit to the training subset, some categories that appeared on the later parts of the dataset (validation/test subsets) were possibly unseen by these <code class="docutils literal notranslate"><span class="pre">LabelEncoder</span></code>s. Hence, the encodings we applied allocated/appended a new label
index for each unseen category, and here we somehow <em>“inform”</em> the model the precise number of categories the model will need to embed for each attribute.</p>
<p>Adding the input structure we inferred to the configuration object:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">configuration</span><span class="p">[</span><span class="s1">&#39;data_props&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">structure</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Model-Creation-and-Initiation">
<h3>Model Creation and Initiation<a class="headerlink" href="#Model-Creation-and-Initiation" title="Permalink to this headline">¶</a></h3>
<p>The model is initiated by the configuration created above:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">model</span> <span class="o">=</span> <span class="n">TemporalFusionTransformer</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="n">OmegaConf</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="n">configuration</span><span class="p">))</span>
</pre></div>
</div>
</div>
<p>For initialization of the weights composing the model, we use the legendary <a class="reference external" href="https://gist.github.com/jeasinema/ed9236ce743c8efaf30fa2ff732749f5">snippet/gist</a> provided by <a class="reference external" href="https://gist.github.com/jeasinema">jeasinema</a>:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">weight_init</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Usage:</span>
<span class="sd">        model = Model()</span>
<span class="sd">        model.apply(weight_init)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">):</span>
        <span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">m</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">):</span>
        <span class="n">init</span><span class="o">.</span><span class="n">xavier_normal_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">m</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv3d</span><span class="p">):</span>
        <span class="n">init</span><span class="o">.</span><span class="n">xavier_normal_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">m</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose1d</span><span class="p">):</span>
        <span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">m</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">):</span>
        <span class="n">init</span><span class="o">.</span><span class="n">xavier_normal_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">m</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose3d</span><span class="p">):</span>
        <span class="n">init</span><span class="o">.</span><span class="n">xavier_normal_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">m</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">):</span>
        <span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="mf">0.02</span><span class="p">)</span>
        <span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">):</span>
        <span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="mf">0.02</span><span class="p">)</span>
        <span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm3d</span><span class="p">):</span>
        <span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="mf">0.02</span><span class="p">)</span>
        <span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">):</span>
        <span class="n">init</span><span class="o">.</span><span class="n">xavier_normal_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">m</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">2</span><span class="p">:</span>
                <span class="n">init</span><span class="o">.</span><span class="n">orthogonal_</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTMCell</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">2</span><span class="p">:</span>
                <span class="n">init</span><span class="o">.</span><span class="n">orthogonal_</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">2</span><span class="p">:</span>
                <span class="n">init</span><span class="o">.</span><span class="n">orthogonal_</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">names</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">_all_weights</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">n</span><span class="p">:</span> <span class="s2">&quot;bias&quot;</span> <span class="ow">in</span> <span class="n">n</span><span class="p">,</span> <span class="n">names</span><span class="p">):</span>
                <span class="n">bias</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
                <span class="n">n</span> <span class="o">=</span> <span class="n">bias</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                <span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="p">[:</span><span class="n">n</span> <span class="o">//</span> <span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="o">-</span><span class="mf">1.</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRUCell</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">2</span><span class="p">:</span>
                <span class="n">init</span><span class="o">.</span><span class="n">orthogonal_</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">model</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">weight_init</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Then we specify the device, according to the availability of <em>CUDA</em> device, and transfer the model to the device accordingly:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">is_cuda</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">is_cuda</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Now that the model is set, we initalize the optimizer, and point it to the model parameters:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">opt</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">p</span><span class="p">:</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())),</span>
                <span class="n">lr</span><span class="o">=</span><span class="n">configuration</span><span class="p">[</span><span class="s1">&#39;optimization&#39;</span><span class="p">][</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Data-Preparation">
<h3>Data Preparation<a class="headerlink" href="#Data-Preparation" title="Permalink to this headline">¶</a></h3>
<p>As a utility class, we will declare <code class="docutils literal notranslate"><span class="pre">DictDataSet</span></code> which digests a dictionary of numpy arrays, and makes sure that each record/observation that will be retrieved using this dataset, will be output as a dictionary of tensors with keys corresponding to these of the original input dictionary. This <code class="docutils literal notranslate"><span class="pre">DictDataSet</span></code> be useful because when we’ll wrap it with a dedicated <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code> object, our mini-batches will be <code class="docutils literal notranslate"><span class="pre">dict</span></code> objects as well, which is highly convenient. <strong>Note</strong>: The tensor data-types
are set according to the data-type of the corresponding numpy arrays.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">class</span> <span class="nc">DictDataSet</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">array_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">keys_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">array_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">keys_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">issubdtype</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="s1">&#39;bool&#39;</span><span class="p">)):</span>
                <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">ByteTensor</span><span class="p">(</span><span class="n">v</span><span class="p">))</span>
            <span class="k">elif</span> <span class="n">np</span><span class="o">.</span><span class="n">issubdtype</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">int8</span><span class="p">):</span>
                <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">CharTensor</span><span class="p">(</span><span class="n">v</span><span class="p">))</span>
            <span class="k">elif</span> <span class="n">np</span><span class="o">.</span><span class="n">issubdtype</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">int16</span><span class="p">):</span>
                <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">ShortTensor</span><span class="p">(</span><span class="n">v</span><span class="p">))</span>
            <span class="k">elif</span> <span class="n">np</span><span class="o">.</span><span class="n">issubdtype</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">):</span>
                <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">IntTensor</span><span class="p">(</span><span class="n">v</span><span class="p">))</span>
            <span class="k">elif</span> <span class="n">np</span><span class="o">.</span><span class="n">issubdtype</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">):</span>
                <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">v</span><span class="p">))</span>
            <span class="k">elif</span> <span class="n">np</span><span class="o">.</span><span class="n">issubdtype</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">):</span>
                <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">v</span><span class="p">))</span>
            <span class="k">elif</span> <span class="n">np</span><span class="o">.</span><span class="n">issubdtype</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">):</span>
                <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">DoubleTensor</span><span class="p">(</span><span class="n">v</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">v</span><span class="p">))</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">)[</span><span class="n">index</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">keys_list</span><span class="p">}</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">keys_list</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
<p>In addition, we’ll define a function named <code class="docutils literal notranslate"><span class="pre">recycle</span></code>, which will be used for creating some kind of “<em>infinite</em>” data loader, i.e. by wrapping a dataloader with this utility function, we make sure that we’ll be able to get batches (using e.g. <code class="docutils literal notranslate"><span class="pre">next</span></code>), and the iterator won’t get to its ending state.</p>
<p>One last utility data-related utility function is <code class="docutils literal notranslate"><span class="pre">get_set_and_loaders()</span></code>, which expects a <code class="docutils literal notranslate"><span class="pre">dict</span></code> of numpy arrays, transforms it into a <code class="docutils literal notranslate"><span class="pre">DictDataSet</span></code> object, and creates two data loaders for each set. One data loader will be shuffled and, what was termed as “<em>infinite</em>”, and the second one will be serial, for allowing us to perform inference on all the observations in the dataset, while keeping them in the original order. <em>Note</em>: the input argument <code class="docutils literal notranslate"><span class="pre">ignore_keys</span></code> allows discarding some
keys in the original dictionary, <code class="docutils literal notranslate"><span class="pre">data_dict</span></code>, and not including them in the resulting <code class="docutils literal notranslate"><span class="pre">DictDataSet</span></code> and in the corresponding batches it’ll produce.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">recycle</span><span class="p">(</span><span class="n">iterable</span><span class="p">):</span>
    <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">iterable</span><span class="p">:</span>
            <span class="k">yield</span> <span class="n">x</span>

<span class="k">def</span> <span class="nf">get_set_and_loaders</span><span class="p">(</span><span class="n">data_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
                        <span class="n">shuffled_loader_config</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span>
                        <span class="n">serial_loader_config</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span>
                        <span class="n">ignore_keys</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                        <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">]:</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">DictDataSet</span><span class="p">({</span><span class="n">k</span><span class="p">:</span><span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="n">data_dict</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="p">(</span><span class="n">ignore_keys</span> <span class="ow">and</span> <span class="n">k</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">ignore_keys</span><span class="p">)})</span>
    <span class="n">loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span><span class="o">**</span><span class="n">shuffled_loader_config</span><span class="p">)</span>
    <span class="n">serial_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span><span class="o">**</span><span class="n">serial_loader_config</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">dataset</span><span class="p">,</span><span class="nb">iter</span><span class="p">(</span><span class="n">recycle</span><span class="p">(</span><span class="n">loader</span><span class="p">)),</span><span class="n">serial_loader</span>
</pre></div>
</div>
</div>
<p>We set the configuration for the shuffled data loaders, and for the serial ones, and we also set the <code class="docutils literal notranslate"><span class="pre">meta_keys</span></code> which specifies which keys do not contain actual data (only meta-data to identify each record):</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">shuffled_loader_config</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="n">configuration</span><span class="p">[</span><span class="s1">&#39;optimization&#39;</span><span class="p">][</span><span class="s1">&#39;batch_size&#39;</span><span class="p">][</span><span class="s1">&#39;training&#39;</span><span class="p">],</span>
                <span class="s1">&#39;drop_last&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                <span class="s1">&#39;shuffle&#39;</span><span class="p">:</span><span class="kc">True</span><span class="p">}</span>

<span class="n">serial_loader_config</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="n">configuration</span><span class="p">[</span><span class="s1">&#39;optimization&#39;</span><span class="p">][</span><span class="s1">&#39;batch_size&#39;</span><span class="p">][</span><span class="s1">&#39;inference&#39;</span><span class="p">],</span>
                <span class="s1">&#39;drop_last&#39;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
                <span class="s1">&#39;shuffle&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">}</span>

<span class="c1"># the following fields do not contain actual data, but are only identifiers of each observation</span>
<span class="n">meta_keys</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;time_index&#39;</span><span class="p">,</span><span class="s1">&#39;combination_id&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<p>We use the utility functions for generating the required data loaders for each of the subsets:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">train_set</span><span class="p">,</span><span class="n">train_loader</span><span class="p">,</span><span class="n">train_serial_loader</span> <span class="o">=</span> <span class="n">get_set_and_loaders</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;data_sets&#39;</span><span class="p">][</span><span class="s1">&#39;train&#39;</span><span class="p">],</span>
                                                                <span class="n">shuffled_loader_config</span><span class="p">,</span>
                                                                <span class="n">serial_loader_config</span><span class="p">,</span>
                                                                <span class="n">ignore_keys</span><span class="o">=</span><span class="n">meta_keys</span><span class="p">)</span>
<span class="n">validation_set</span><span class="p">,</span><span class="n">validation_loader</span><span class="p">,</span><span class="n">validation_serial_loader</span> <span class="o">=</span> <span class="n">get_set_and_loaders</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;data_sets&#39;</span><span class="p">][</span><span class="s1">&#39;validation&#39;</span><span class="p">],</span>
                                                                <span class="n">shuffled_loader_config</span><span class="p">,</span>
                                                                <span class="n">serial_loader_config</span><span class="p">,</span>
                                                                <span class="n">ignore_keys</span><span class="o">=</span><span class="n">meta_keys</span><span class="p">)</span>
<span class="n">test_set</span><span class="p">,</span><span class="n">test_loader</span><span class="p">,</span><span class="n">test_serial_loader</span> <span class="o">=</span> <span class="n">get_set_and_loaders</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;data_sets&#39;</span><span class="p">][</span><span class="s1">&#39;test&#39;</span><span class="p">],</span>
                                                                <span class="n">shuffled_loader_config</span><span class="p">,</span>
                                                                <span class="n">serial_loader_config</span><span class="p">,</span>
                                                                <span class="n">ignore_keys</span><span class="o">=</span><span class="n">meta_keys</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Training-Procedure">
<h3>Training Procedure<a class="headerlink" href="#Training-Procedure" title="Permalink to this headline">¶</a></h3>
<p>Now that everything is set in terms of the model and the data, we define some helpful utilities for easier orchestration of the training procedure.</p>
<p><code class="docutils literal notranslate"><span class="pre">QueueAggregator</span></code> is, well, a queue, which will be used as a running-window aggregator of the training performance metric. We’ll use it to for smoother (and less noisier) estimation of our loss during training.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[22]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">class</span> <span class="nc">QueueAggregator</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">max_size</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_queued_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_size</span> <span class="o">=</span> <span class="n">max_size</span>

    <span class="k">def</span> <span class="nf">append</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">elem</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_queued_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">elem</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_queued_list</span><span class="p">)</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_size</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_queued_list</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_queued_list</span>
</pre></div>
</div>
</div>
<p>We also employ an <code class="docutils literal notranslate"><span class="pre">EarlyStopping</span></code> mechanism for monitoring the performance on our validation set, and indicate when can we quit training. This extremely <a class="reference external" href="https://gist.github.com/stefanonardo/693d96ceb2f531fa05db530f3e21517d">useful snippet</a> was originally contributed by <a class="reference external" href="https://gist.github.com/stefanonardo">stefanonardo</a>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">class</span> <span class="nc">EarlyStopping</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;min&#39;</span><span class="p">,</span> <span class="n">min_delta</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">percentage</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="n">mode</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">min_delta</span> <span class="o">=</span> <span class="n">min_delta</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">patience</span> <span class="o">=</span> <span class="n">patience</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">best</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_bad_epochs</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_better</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_init_is_better</span><span class="p">(</span><span class="n">mode</span><span class="p">,</span> <span class="n">min_delta</span><span class="p">,</span> <span class="n">percentage</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">patience</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">is_better</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="kc">True</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">step</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">a</span><span class="p">:</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">metrics</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">best</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">best</span> <span class="o">=</span> <span class="n">metrics</span>
            <span class="k">return</span> <span class="kc">False</span>

        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">metrics</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">True</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_better</span><span class="p">(</span><span class="n">metrics</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">best</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">num_bad_epochs</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">best</span> <span class="o">=</span> <span class="n">metrics</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">num_bad_epochs</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_bad_epochs</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">patience</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">True</span>

        <span class="k">return</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="nf">_init_is_better</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">min_delta</span><span class="p">,</span> <span class="n">percentage</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">mode</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">{</span><span class="s1">&#39;min&#39;</span><span class="p">,</span> <span class="s1">&#39;max&#39;</span><span class="p">}:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;mode &#39;</span> <span class="o">+</span> <span class="n">mode</span> <span class="o">+</span> <span class="s1">&#39; is unknown!&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">percentage</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;min&#39;</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">is_better</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">a</span><span class="p">,</span> <span class="n">best</span><span class="p">:</span> <span class="n">a</span> <span class="o">&lt;</span> <span class="n">best</span> <span class="o">-</span> <span class="n">min_delta</span>
            <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;max&#39;</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">is_better</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">a</span><span class="p">,</span> <span class="n">best</span><span class="p">:</span> <span class="n">a</span> <span class="o">&gt;</span> <span class="n">best</span> <span class="o">+</span> <span class="n">min_delta</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;min&#39;</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">is_better</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">a</span><span class="p">,</span> <span class="n">best</span><span class="p">:</span> <span class="n">a</span> <span class="o">&lt;</span> <span class="n">best</span> <span class="o">-</span> <span class="p">(</span>
                            <span class="n">best</span> <span class="o">*</span> <span class="n">min_delta</span> <span class="o">/</span> <span class="mi">100</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;max&#39;</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">is_better</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">a</span><span class="p">,</span> <span class="n">best</span><span class="p">:</span> <span class="n">a</span> <span class="o">&gt;</span> <span class="n">best</span> <span class="o">+</span> <span class="p">(</span>
                            <span class="n">best</span> <span class="o">*</span> <span class="n">min_delta</span> <span class="o">/</span> <span class="mi">100</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="Training-Settings">
<h2>Training Settings<a class="headerlink" href="#Training-Settings" title="Permalink to this headline">¶</a></h2>
<p>Let’s go over to required parameters which will control the training routine:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># If early stopping is not triggered, after how many epochs should we quit training</span>
<span class="n">max_epochs</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="c1"># how many training batches will compose a single training epoch</span>
<span class="n">epoch_iters</span> <span class="o">=</span> <span class="mi">200</span>
<span class="c1"># upon completing a training epoch, we perform an evaluation of all the subsets</span>
<span class="c1"># eval_iters will define how many batches of each set will compose a single evaluation round</span>
<span class="n">eval_iters</span> <span class="o">=</span> <span class="mi">500</span>
<span class="c1"># during training, on what frequency should we display the monitored performance</span>
<span class="n">log_interval</span> <span class="o">=</span> <span class="mi">20</span>
<span class="c1"># what is the running-window used by our QueueAggregator object for monitoring the training performance</span>
<span class="n">ma_queue_size</span> <span class="o">=</span> <span class="mi">50</span>
<span class="c1"># how many evaluation rounds should we allow,</span>
<span class="c1"># without any improvement in the performance observed on the validation set</span>
<span class="n">patience</span> <span class="o">=</span> <span class="mi">5</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[25]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># initialize early stopping mechanism</span>
<span class="n">es</span> <span class="o">=</span> <span class="n">EarlyStopping</span><span class="p">(</span><span class="n">patience</span><span class="o">=</span><span class="n">patience</span><span class="p">)</span>
<span class="c1"># initialize the loss aggregator for running window performance estimation</span>
<span class="n">loss_aggregator</span> <span class="o">=</span> <span class="n">QueueAggregator</span><span class="p">(</span><span class="n">max_size</span><span class="o">=</span><span class="n">ma_queue_size</span><span class="p">)</span>

<span class="c1"># initialize counters</span>
<span class="n">batch_idx</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">epoch_idx</span> <span class="o">=</span> <span class="mi">0</span>
</pre></div>
</div>
</div>
<p>For computing the loss we are seeking to optimize, we need to define a tensor, corresponding to the actual quantiles we want to estimate:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[26]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">quantiles_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">configuration</span><span class="p">[</span><span class="s1">&#39;model&#39;</span><span class="p">][</span><span class="s1">&#39;output_quantiles&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>The following cell implements the way each batch is processed by our training/evaluation procedure. We transfer each batch component to the <code class="docutils literal notranslate"><span class="pre">device</span></code> we’re using, feed the batch to the model, and compute the loss, using the labels (which are part of our batch), the <code class="docutils literal notranslate"><span class="pre">predicted_quantiles</span></code> output, and the <em>fixed</em> tensor <code class="docutils literal notranslate"><span class="pre">quantiles_tensor</span></code> stating the quantiles we wish to estimate.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[27]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">process_batch</span><span class="p">(</span><span class="n">batch</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">],</span>
                  <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
                  <span class="n">quantiles_tensor</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">,</span>
                  <span class="n">device</span><span class="p">:</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">is_cuda</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">batch</span><span class="o">.</span><span class="n">keys</span><span class="p">()):</span>
            <span class="n">batch</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="n">batch_outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span>

    <span class="n">predicted_quantiles</span> <span class="o">=</span> <span class="n">batch_outputs</span><span class="p">[</span><span class="s1">&#39;predicted_quantiles&#39;</span><span class="p">]</span>
    <span class="n">q_loss</span><span class="p">,</span> <span class="n">q_risk</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">tft_loss</span><span class="o">.</span><span class="n">get_quantiles_loss_and_q_risk</span><span class="p">(</span><span class="n">outputs</span><span class="o">=</span><span class="n">predicted_quantiles</span><span class="p">,</span>
                                                              <span class="n">targets</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
                                                              <span class="n">desired_quantiles</span><span class="o">=</span><span class="n">quantiles_tensor</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">q_loss</span><span class="p">,</span> <span class="n">q_risk</span>
</pre></div>
</div>
</div>
<p>Now, finally, is the actual training loop. This loop will go on until completing <code class="docutils literal notranslate"><span class="pre">max_epoch</span></code> rounds, or until <code class="docutils literal notranslate"><span class="pre">EarlyStopping</span></code> is triggered.</p>
<p>Each epoch starts with the evaluation of each of the subsets. Each evaluation rounds includes the processing of <code class="docutils literal notranslate"><span class="pre">eval_iters</span></code> batches from the relevant subset, after which the losses and the metrics are concatenated and averaged. The loss computed for the validation set is fed to the early stopping mechanism for continuous tracking.</p>
<p>After completing the evaluation of the data subsets, a training round, including the processing of <code class="docutils literal notranslate"><span class="pre">epoch_iters</span></code> batches from the training subset, is initiated. For each training batch, the computed loss is used for calling the optimizer to update the model weights, and added to the loss aggregator.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[28]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">while</span> <span class="n">epoch_idx</span> <span class="o">&lt;</span> <span class="n">max_epochs</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Starting Epoch Index </span><span class="si">{</span><span class="n">epoch_idx</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># evaluation round</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="c1"># for each subset</span>
        <span class="k">for</span> <span class="n">subset_name</span><span class="p">,</span> <span class="n">subset_loader</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">([</span><span class="s1">&#39;train&#39;</span><span class="p">,</span><span class="s1">&#39;validation&#39;</span><span class="p">,</span><span class="s1">&#39;test&#39;</span><span class="p">],[</span><span class="n">train_loader</span><span class="p">,</span><span class="n">validation_loader</span><span class="p">,</span><span class="n">test_loader</span><span class="p">]):</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Evaluating </span><span class="si">{</span><span class="n">subset_name</span><span class="si">}</span><span class="s2"> set&quot;</span><span class="p">)</span>

            <span class="n">q_loss_vals</span><span class="p">,</span> <span class="n">q_risk_vals</span> <span class="o">=</span> <span class="p">[],[]</span> <span class="c1"># used for aggregating performance along the evaluation round</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">eval_iters</span><span class="p">):</span>
                <span class="c1"># get batch</span>
                <span class="n">batch</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">subset_loader</span><span class="p">)</span>
                <span class="c1"># process batch</span>
                <span class="n">batch_loss</span><span class="p">,</span><span class="n">batch_q_risk</span> <span class="o">=</span> <span class="n">process_batch</span><span class="p">(</span><span class="n">batch</span><span class="o">=</span><span class="n">batch</span><span class="p">,</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span><span class="n">quantiles_tensor</span><span class="o">=</span><span class="n">quantiles_tensor</span><span class="p">,</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
                <span class="c1"># accumulate performance</span>
                <span class="n">q_loss_vals</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">batch_loss</span><span class="p">)</span>
                <span class="n">q_risk_vals</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">batch_q_risk</span><span class="p">)</span>

            <span class="c1"># aggregate and average</span>
            <span class="n">eval_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">q_loss_vals</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">eval_q_risk</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">q_risk_vals</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

            <span class="c1"># keep for feeding the early stopping mechanism</span>
            <span class="k">if</span> <span class="n">subset_name</span> <span class="o">==</span> <span class="s1">&#39;validation&#39;</span><span class="p">:</span>
                <span class="n">validation_loss</span> <span class="o">=</span> <span class="n">eval_loss</span>

            <span class="c1"># log performance</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch: </span><span class="si">{</span><span class="n">epoch_idx</span><span class="si">}</span><span class="s2">, Batch Index: </span><span class="si">{</span><span class="n">batch_idx</span><span class="si">}</span><span class="s2">&quot;</span> <span class="o">+</span> \
                  <span class="sa">f</span><span class="s2">&quot;- Eval </span><span class="si">{</span><span class="n">subset_name</span><span class="si">}</span><span class="s2"> - &quot;</span> <span class="o">+</span> \
                  <span class="sa">f</span><span class="s2">&quot;q_loss = </span><span class="si">{</span><span class="n">eval_loss</span><span class="si">:</span><span class="s2">.5f</span><span class="si">}</span><span class="s2"> , &quot;</span> <span class="o">+</span> \
                  <span class="s2">&quot; , &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="sa">f</span><span class="s2">&quot;q_risk_</span><span class="si">{</span><span class="n">q</span><span class="si">:</span><span class="s2">.1</span><span class="si">}</span><span class="s2"> = </span><span class="si">{</span><span class="n">risk</span><span class="si">:</span><span class="s2">.5f</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">q</span><span class="p">,</span><span class="n">risk</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">quantiles_tensor</span><span class="p">,</span><span class="n">eval_q_risk</span><span class="p">)]))</span>

    <span class="c1"># switch to training mode</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

    <span class="c1"># update early stopping mechanism and stop if triggered</span>
    <span class="k">if</span> <span class="n">es</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">validation_loss</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Performing early stopping...!&#39;</span><span class="p">)</span>
        <span class="k">break</span>

    <span class="c1"># initiating a training round</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epoch_iters</span><span class="p">):</span>
        <span class="c1"># get training batch</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>

        <span class="n">opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="c1"># process batch</span>
        <span class="n">loss</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">process_batch</span><span class="p">(</span><span class="n">batch</span><span class="o">=</span><span class="n">batch</span><span class="p">,</span>
                              <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
                              <span class="n">quantiles_tensor</span><span class="o">=</span><span class="n">quantiles_tensor</span><span class="p">,</span>
                              <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        <span class="c1"># compute gradients</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="c1"># gradient clipping</span>
        <span class="k">if</span> <span class="n">configuration</span><span class="p">[</span><span class="s1">&#39;optimization&#39;</span><span class="p">][</span><span class="s1">&#39;max_grad_norm&#39;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">configuration</span><span class="p">[</span><span class="s1">&#39;optimization&#39;</span><span class="p">][</span><span class="s1">&#39;max_grad_norm&#39;</span><span class="p">])</span>
        <span class="c1"># update weights</span>
        <span class="n">opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="c1"># accumulate performance</span>
        <span class="n">loss_aggregator</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

        <span class="c1"># log performance</span>
        <span class="k">if</span> <span class="n">batch_idx</span> <span class="o">%</span> <span class="n">log_interval</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch: </span><span class="si">{</span><span class="n">epoch_idx</span><span class="si">}</span><span class="s2">, Batch Index: </span><span class="si">{</span><span class="n">batch_idx</span><span class="si">}</span><span class="s2"> - Train Loss = </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">loss_aggregator</span><span class="o">.</span><span class="n">get</span><span class="p">())</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># completed batch</span>
        <span class="n">batch_idx</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="c1"># completed epoch</span>
    <span class="n">epoch_idx</span> <span class="o">+=</span> <span class="mi">1</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Starting Epoch Index 0
Evaluating train set
Epoch: 0, Batch Index: 0- Eval train - q_loss = 2.03305 , q_risk_0.1 = 2.15217 , q_risk_0.5 = 1.50869 , q_risk_0.9 = 1.42569
Evaluating validation set
Epoch: 0, Batch Index: 0- Eval validation - q_loss = 2.09707 , q_risk_0.1 = 2.79929 , q_risk_0.5 = 1.31844 , q_risk_0.9 = 1.11522
Evaluating test set
Epoch: 0, Batch Index: 0- Eval test - q_loss = 1.98208 , q_risk_0.1 = 2.24149 , q_risk_0.5 = 1.40397 , q_risk_0.9 = 1.35933
Epoch: 0, Batch Index: 0 - Train Loss = 2.020455837249756
Epoch: 0, Batch Index: 20 - Train Loss = 0.7724506230581374
Epoch: 0, Batch Index: 40 - Train Loss = 0.6347503349548433
Epoch: 0, Batch Index: 60 - Train Loss = 0.5004462844133377
Epoch: 0, Batch Index: 80 - Train Loss = 0.44857171654701233
Epoch: 0, Batch Index: 100 - Train Loss = 0.43766250789165495
Epoch: 0, Batch Index: 120 - Train Loss = 0.43416002750396726
Epoch: 0, Batch Index: 140 - Train Loss = 0.4331358313560486
Epoch: 0, Batch Index: 160 - Train Loss = 0.43066891729831697
Epoch: 0, Batch Index: 180 - Train Loss = 0.42729145765304566
Starting Epoch Index 1
Evaluating train set
Epoch: 1, Batch Index: 200- Eval train - q_loss = 0.42002 , q_risk_0.1 = 0.23620 , q_risk_0.5 = 0.56292 , q_risk_0.9 = 0.25254
Evaluating validation set
Epoch: 1, Batch Index: 200- Eval validation - q_loss = 0.39472 , q_risk_0.1 = 0.20502 , q_risk_0.5 = 0.53681 , q_risk_0.9 = 0.24385
Evaluating test set
Epoch: 1, Batch Index: 200- Eval test - q_loss = 0.43020 , q_risk_0.1 = 0.23920 , q_risk_0.5 = 0.58177 , q_risk_0.9 = 0.26610
Epoch: 1, Batch Index: 200 - Train Loss = 0.42498995423316954
Epoch: 1, Batch Index: 220 - Train Loss = 0.42323225796222685
Epoch: 1, Batch Index: 240 - Train Loss = 0.4226619130373001
Epoch: 1, Batch Index: 260 - Train Loss = 0.4221925890445709
Epoch: 1, Batch Index: 280 - Train Loss = 0.42066602885723114
Epoch: 1, Batch Index: 300 - Train Loss = 0.41808026492595673
Epoch: 1, Batch Index: 320 - Train Loss = 0.4159805303812027
Epoch: 1, Batch Index: 340 - Train Loss = 0.4174565130472183
Epoch: 1, Batch Index: 360 - Train Loss = 0.4196115469932556
Epoch: 1, Batch Index: 380 - Train Loss = 0.42100709676742554
Starting Epoch Index 2
Evaluating train set
Epoch: 2, Batch Index: 400- Eval train - q_loss = 0.41395 , q_risk_0.1 = 0.23116 , q_risk_0.5 = 0.55721 , q_risk_0.9 = 0.24765
Evaluating validation set
Epoch: 2, Batch Index: 400- Eval validation - q_loss = 0.38804 , q_risk_0.1 = 0.20017 , q_risk_0.5 = 0.52711 , q_risk_0.9 = 0.24130
Evaluating test set
Epoch: 2, Batch Index: 400- Eval test - q_loss = 0.42346 , q_risk_0.1 = 0.23246 , q_risk_0.5 = 0.57313 , q_risk_0.9 = 0.26003
Epoch: 2, Batch Index: 400 - Train Loss = 0.4180942130088806
Epoch: 2, Batch Index: 420 - Train Loss = 0.41510038435459135
Epoch: 2, Batch Index: 440 - Train Loss = 0.41567377269268035
Epoch: 2, Batch Index: 460 - Train Loss = 0.41648059606552124
Epoch: 2, Batch Index: 480 - Train Loss = 0.41558587193489077
Epoch: 2, Batch Index: 500 - Train Loss = 0.4143910664319992
Epoch: 2, Batch Index: 520 - Train Loss = 0.41360773086547853
Epoch: 2, Batch Index: 540 - Train Loss = 0.4148547148704529
Epoch: 2, Batch Index: 560 - Train Loss = 0.41554462850093843
Epoch: 2, Batch Index: 580 - Train Loss = 0.4137012666463852
Starting Epoch Index 3
Evaluating train set
Epoch: 3, Batch Index: 600- Eval train - q_loss = 0.40949 , q_risk_0.1 = 0.22791 , q_risk_0.5 = 0.55206 , q_risk_0.9 = 0.24633
Evaluating validation set
Epoch: 3, Batch Index: 600- Eval validation - q_loss = 0.38416 , q_risk_0.1 = 0.19762 , q_risk_0.5 = 0.52276 , q_risk_0.9 = 0.23902
Evaluating test set
Epoch: 3, Batch Index: 600- Eval test - q_loss = 0.41854 , q_risk_0.1 = 0.23092 , q_risk_0.5 = 0.56851 , q_risk_0.9 = 0.25763
Epoch: 3, Batch Index: 600 - Train Loss = 0.41306958615779876
Epoch: 3, Batch Index: 620 - Train Loss = 0.41319740533828736
Epoch: 3, Batch Index: 640 - Train Loss = 0.41450446128845214
Epoch: 3, Batch Index: 660 - Train Loss = 0.4108119714260101
Epoch: 3, Batch Index: 680 - Train Loss = 0.40992509841918945
Epoch: 3, Batch Index: 700 - Train Loss = 0.4079200464487076
Epoch: 3, Batch Index: 720 - Train Loss = 0.409369660615921
Epoch: 3, Batch Index: 740 - Train Loss = 0.4104118537902832
Epoch: 3, Batch Index: 760 - Train Loss = 0.4100472277402878
Epoch: 3, Batch Index: 780 - Train Loss = 0.4100530457496643
Starting Epoch Index 4
Evaluating train set
Epoch: 4, Batch Index: 800- Eval train - q_loss = 0.40630 , q_risk_0.1 = 0.22670 , q_risk_0.5 = 0.54644 , q_risk_0.9 = 0.24413
Evaluating validation set
Epoch: 4, Batch Index: 800- Eval validation - q_loss = 0.38275 , q_risk_0.1 = 0.19644 , q_risk_0.5 = 0.51953 , q_risk_0.9 = 0.24003
Evaluating test set
Epoch: 4, Batch Index: 800- Eval test - q_loss = 0.41674 , q_risk_0.1 = 0.22941 , q_risk_0.5 = 0.56476 , q_risk_0.9 = 0.25801
Epoch: 4, Batch Index: 800 - Train Loss = 0.40925871193408964
Epoch: 4, Batch Index: 820 - Train Loss = 0.4090828377008438
Epoch: 4, Batch Index: 840 - Train Loss = 0.4069894003868103
Epoch: 4, Batch Index: 860 - Train Loss = 0.40759585201740267
Epoch: 4, Batch Index: 880 - Train Loss = 0.4058069509267807
Epoch: 4, Batch Index: 900 - Train Loss = 0.40712576448917387
Epoch: 4, Batch Index: 920 - Train Loss = 0.40775597989559176
Epoch: 4, Batch Index: 940 - Train Loss = 0.4076818293333054
Epoch: 4, Batch Index: 960 - Train Loss = 0.40606608867645266
Epoch: 4, Batch Index: 980 - Train Loss = 0.4045009380578995
Starting Epoch Index 5
Evaluating train set
Epoch: 5, Batch Index: 1000- Eval train - q_loss = 0.40445 , q_risk_0.1 = 0.22491 , q_risk_0.5 = 0.54649 , q_risk_0.9 = 0.24098
Evaluating validation set
Epoch: 5, Batch Index: 1000- Eval validation - q_loss = 0.38038 , q_risk_0.1 = 0.19408 , q_risk_0.5 = 0.51852 , q_risk_0.9 = 0.23671
Evaluating test set
Epoch: 5, Batch Index: 1000- Eval test - q_loss = 0.41440 , q_risk_0.1 = 0.22713 , q_risk_0.5 = 0.56470 , q_risk_0.9 = 0.25405
Epoch: 5, Batch Index: 1000 - Train Loss = 0.4067613816261291
Epoch: 5, Batch Index: 1020 - Train Loss = 0.4067066353559494
Epoch: 5, Batch Index: 1040 - Train Loss = 0.40532047510147096
Epoch: 5, Batch Index: 1060 - Train Loss = 0.4045089113712311
Epoch: 5, Batch Index: 1080 - Train Loss = 0.4038675820827484
Epoch: 5, Batch Index: 1100 - Train Loss = 0.4051359671354294
Epoch: 5, Batch Index: 1120 - Train Loss = 0.40533805549144747
Epoch: 5, Batch Index: 1140 - Train Loss = 0.4062341320514679
Epoch: 5, Batch Index: 1160 - Train Loss = 0.40499836564064023
Epoch: 5, Batch Index: 1180 - Train Loss = 0.4051413434743881
Starting Epoch Index 6
Evaluating train set
Epoch: 6, Batch Index: 1200- Eval train - q_loss = 0.40266 , q_risk_0.1 = 0.22359 , q_risk_0.5 = 0.54319 , q_risk_0.9 = 0.23855
Evaluating validation set
Epoch: 6, Batch Index: 1200- Eval validation - q_loss = 0.38021 , q_risk_0.1 = 0.19417 , q_risk_0.5 = 0.51992 , q_risk_0.9 = 0.23482
Evaluating test set
Epoch: 6, Batch Index: 1200- Eval test - q_loss = 0.41308 , q_risk_0.1 = 0.22795 , q_risk_0.5 = 0.56358 , q_risk_0.9 = 0.25170
Epoch: 6, Batch Index: 1200 - Train Loss = 0.40418831825256346
Epoch: 6, Batch Index: 1220 - Train Loss = 0.40468450009822843
Epoch: 6, Batch Index: 1240 - Train Loss = 0.4058254724740982
Epoch: 6, Batch Index: 1260 - Train Loss = 0.4060604375600815
Epoch: 6, Batch Index: 1280 - Train Loss = 0.4070625078678131
Epoch: 6, Batch Index: 1300 - Train Loss = 0.40513818204402924
Epoch: 6, Batch Index: 1320 - Train Loss = 0.40423076212406156
Epoch: 6, Batch Index: 1340 - Train Loss = 0.40216550648212435
Epoch: 6, Batch Index: 1360 - Train Loss = 0.4020002579689026
Epoch: 6, Batch Index: 1380 - Train Loss = 0.40282262206077574
Starting Epoch Index 7
Evaluating train set
Epoch: 7, Batch Index: 1400- Eval train - q_loss = 0.39914 , q_risk_0.1 = 0.22295 , q_risk_0.5 = 0.53990 , q_risk_0.9 = 0.23707
Evaluating validation set
Epoch: 7, Batch Index: 1400- Eval validation - q_loss = 0.37719 , q_risk_0.1 = 0.19344 , q_risk_0.5 = 0.51450 , q_risk_0.9 = 0.23325
Evaluating test set
Epoch: 7, Batch Index: 1400- Eval test - q_loss = 0.40899 , q_risk_0.1 = 0.22704 , q_risk_0.5 = 0.55840 , q_risk_0.9 = 0.24897
Epoch: 7, Batch Index: 1400 - Train Loss = 0.402779341340065
Epoch: 7, Batch Index: 1420 - Train Loss = 0.40297271132469176
Epoch: 7, Batch Index: 1440 - Train Loss = 0.4026300513744354
Epoch: 7, Batch Index: 1460 - Train Loss = 0.40316272258758545
Epoch: 7, Batch Index: 1480 - Train Loss = 0.4022568541765213
Epoch: 7, Batch Index: 1500 - Train Loss = 0.4006280392408371
Epoch: 7, Batch Index: 1520 - Train Loss = 0.4012106776237488
Epoch: 7, Batch Index: 1540 - Train Loss = 0.40098224580287933
Epoch: 7, Batch Index: 1560 - Train Loss = 0.4003554481267929
Epoch: 7, Batch Index: 1580 - Train Loss = 0.40120102822780607
Starting Epoch Index 8
Evaluating train set
Epoch: 8, Batch Index: 1600- Eval train - q_loss = 0.39869 , q_risk_0.1 = 0.22295 , q_risk_0.5 = 0.54067 , q_risk_0.9 = 0.23733
Evaluating validation set
Epoch: 8, Batch Index: 1600- Eval validation - q_loss = 0.37542 , q_risk_0.1 = 0.19315 , q_risk_0.5 = 0.51215 , q_risk_0.9 = 0.23249
Evaluating test set
Epoch: 8, Batch Index: 1600- Eval test - q_loss = 0.40910 , q_risk_0.1 = 0.22636 , q_risk_0.5 = 0.55779 , q_risk_0.9 = 0.24879
Epoch: 8, Batch Index: 1600 - Train Loss = 0.4011056447029114
Epoch: 8, Batch Index: 1620 - Train Loss = 0.4003825575113297
Epoch: 8, Batch Index: 1640 - Train Loss = 0.4013179081678391
Epoch: 8, Batch Index: 1660 - Train Loss = 0.4005914378166199
Epoch: 8, Batch Index: 1680 - Train Loss = 0.400411833524704
Epoch: 8, Batch Index: 1700 - Train Loss = 0.39901186048984527
Epoch: 8, Batch Index: 1720 - Train Loss = 0.39950142443180087
Epoch: 8, Batch Index: 1740 - Train Loss = 0.40104600429534915
Epoch: 8, Batch Index: 1760 - Train Loss = 0.4011937004327774
Epoch: 8, Batch Index: 1780 - Train Loss = 0.3990417116880417
Starting Epoch Index 9
Evaluating train set
Epoch: 9, Batch Index: 1800- Eval train - q_loss = 0.39769 , q_risk_0.1 = 0.22267 , q_risk_0.5 = 0.53573 , q_risk_0.9 = 0.23551
Evaluating validation set
Epoch: 9, Batch Index: 1800- Eval validation - q_loss = 0.37497 , q_risk_0.1 = 0.19375 , q_risk_0.5 = 0.51019 , q_risk_0.9 = 0.23209
Evaluating test set
Epoch: 9, Batch Index: 1800- Eval test - q_loss = 0.40726 , q_risk_0.1 = 0.22613 , q_risk_0.5 = 0.55291 , q_risk_0.9 = 0.24664
Epoch: 9, Batch Index: 1800 - Train Loss = 0.3984821850061417
Epoch: 9, Batch Index: 1820 - Train Loss = 0.39621995747089384
Epoch: 9, Batch Index: 1840 - Train Loss = 0.397534641623497
Epoch: 9, Batch Index: 1860 - Train Loss = 0.39747892796993256
Epoch: 9, Batch Index: 1880 - Train Loss = 0.39800208926200864
Epoch: 9, Batch Index: 1900 - Train Loss = 0.3982150912284851
Epoch: 9, Batch Index: 1920 - Train Loss = 0.3992548805475235
Epoch: 9, Batch Index: 1940 - Train Loss = 0.40012820780277253
Epoch: 9, Batch Index: 1960 - Train Loss = 0.3997068899869919
Epoch: 9, Batch Index: 1980 - Train Loss = 0.3998417049646378
Starting Epoch Index 10
Evaluating train set
Epoch: 10, Batch Index: 2000- Eval train - q_loss = 0.39851 , q_risk_0.1 = 0.22142 , q_risk_0.5 = 0.53672 , q_risk_0.9 = 0.23679
Evaluating validation set
Epoch: 10, Batch Index: 2000- Eval validation - q_loss = 0.37541 , q_risk_0.1 = 0.19174 , q_risk_0.5 = 0.50991 , q_risk_0.9 = 0.23376
Evaluating test set
Epoch: 10, Batch Index: 2000- Eval test - q_loss = 0.40849 , q_risk_0.1 = 0.22410 , q_risk_0.5 = 0.55475 , q_risk_0.9 = 0.24999
Epoch: 10, Batch Index: 2000 - Train Loss = 0.3990354412794113
Epoch: 10, Batch Index: 2020 - Train Loss = 0.3999947690963745
Epoch: 10, Batch Index: 2040 - Train Loss = 0.39858454167842866
Epoch: 10, Batch Index: 2060 - Train Loss = 0.3993226552009583
Epoch: 10, Batch Index: 2080 - Train Loss = 0.3973876845836639
Epoch: 10, Batch Index: 2100 - Train Loss = 0.3981896710395813
Epoch: 10, Batch Index: 2120 - Train Loss = 0.3981538939476013
Epoch: 10, Batch Index: 2140 - Train Loss = 0.3983695012331009
Epoch: 10, Batch Index: 2160 - Train Loss = 0.3958142375946045
Epoch: 10, Batch Index: 2180 - Train Loss = 0.3963635700941086
Starting Epoch Index 11
Evaluating train set
Epoch: 11, Batch Index: 2200- Eval train - q_loss = 0.39731 , q_risk_0.1 = 0.22121 , q_risk_0.5 = 0.53701 , q_risk_0.9 = 0.23767
Evaluating validation set
Epoch: 11, Batch Index: 2200- Eval validation - q_loss = 0.37305 , q_risk_0.1 = 0.19094 , q_risk_0.5 = 0.50848 , q_risk_0.9 = 0.23342
Evaluating test set
Epoch: 11, Batch Index: 2200- Eval test - q_loss = 0.40681 , q_risk_0.1 = 0.22408 , q_risk_0.5 = 0.55368 , q_risk_0.9 = 0.24790
Epoch: 11, Batch Index: 2200 - Train Loss = 0.397286531329155
Epoch: 11, Batch Index: 2220 - Train Loss = 0.3975470417737961
Epoch: 11, Batch Index: 2240 - Train Loss = 0.39717461585998537
Epoch: 11, Batch Index: 2260 - Train Loss = 0.3976611328125
Epoch: 11, Batch Index: 2280 - Train Loss = 0.3975683742761612
Epoch: 11, Batch Index: 2300 - Train Loss = 0.39604835510253905
Epoch: 11, Batch Index: 2320 - Train Loss = 0.39686691462993623
Epoch: 11, Batch Index: 2340 - Train Loss = 0.39791470289230346
Epoch: 11, Batch Index: 2360 - Train Loss = 0.3995424944162369
Epoch: 11, Batch Index: 2380 - Train Loss = 0.39787294566631315
Starting Epoch Index 12
Evaluating train set
Epoch: 12, Batch Index: 2400- Eval train - q_loss = 0.39626 , q_risk_0.1 = 0.22156 , q_risk_0.5 = 0.53379 , q_risk_0.9 = 0.23491
Evaluating validation set
Epoch: 12, Batch Index: 2400- Eval validation - q_loss = 0.37278 , q_risk_0.1 = 0.19257 , q_risk_0.5 = 0.50609 , q_risk_0.9 = 0.23203
Evaluating test set
Epoch: 12, Batch Index: 2400- Eval test - q_loss = 0.40521 , q_risk_0.1 = 0.22495 , q_risk_0.5 = 0.55083 , q_risk_0.9 = 0.24609
Epoch: 12, Batch Index: 2400 - Train Loss = 0.39735854625701905
Epoch: 12, Batch Index: 2420 - Train Loss = 0.397556711435318
Epoch: 12, Batch Index: 2440 - Train Loss = 0.39656793415546415
Epoch: 12, Batch Index: 2460 - Train Loss = 0.3968496644496918
Epoch: 12, Batch Index: 2480 - Train Loss = 0.39582385659217834
Epoch: 12, Batch Index: 2500 - Train Loss = 0.39432197391986845
Epoch: 12, Batch Index: 2520 - Train Loss = 0.3937902343273163
Epoch: 12, Batch Index: 2540 - Train Loss = 0.39579939663410185
Epoch: 12, Batch Index: 2560 - Train Loss = 0.39682712018489835
Epoch: 12, Batch Index: 2580 - Train Loss = 0.39822638154029844
Starting Epoch Index 13
Evaluating train set
Epoch: 13, Batch Index: 2600- Eval train - q_loss = 0.39503 , q_risk_0.1 = 0.22192 , q_risk_0.5 = 0.53106 , q_risk_0.9 = 0.23303
Evaluating validation set
Epoch: 13, Batch Index: 2600- Eval validation - q_loss = 0.37233 , q_risk_0.1 = 0.19380 , q_risk_0.5 = 0.50514 , q_risk_0.9 = 0.23063
Evaluating test set
Epoch: 13, Batch Index: 2600- Eval test - q_loss = 0.40487 , q_risk_0.1 = 0.22607 , q_risk_0.5 = 0.54981 , q_risk_0.9 = 0.24570
Epoch: 13, Batch Index: 2600 - Train Loss = 0.3985908716917038
Epoch: 13, Batch Index: 2620 - Train Loss = 0.39708409547805784
Epoch: 13, Batch Index: 2640 - Train Loss = 0.39565754354000093
Epoch: 13, Batch Index: 2660 - Train Loss = 0.39411513566970824
Epoch: 13, Batch Index: 2680 - Train Loss = 0.39422193586826326
Epoch: 13, Batch Index: 2700 - Train Loss = 0.39611084043979644
Epoch: 13, Batch Index: 2720 - Train Loss = 0.3958034712076187
Epoch: 13, Batch Index: 2740 - Train Loss = 0.3957914996147156
Epoch: 13, Batch Index: 2760 - Train Loss = 0.39552177786827086
Epoch: 13, Batch Index: 2780 - Train Loss = 0.3972522002458572
Starting Epoch Index 14
Evaluating train set
Epoch: 14, Batch Index: 2800- Eval train - q_loss = 0.39454 , q_risk_0.1 = 0.22024 , q_risk_0.5 = 0.53524 , q_risk_0.9 = 0.23390
Evaluating validation set
Epoch: 14, Batch Index: 2800- Eval validation - q_loss = 0.37213 , q_risk_0.1 = 0.18976 , q_risk_0.5 = 0.50818 , q_risk_0.9 = 0.23144
Evaluating test set
Epoch: 14, Batch Index: 2800- Eval test - q_loss = 0.40552 , q_risk_0.1 = 0.22388 , q_risk_0.5 = 0.55365 , q_risk_0.9 = 0.24705
Epoch: 14, Batch Index: 2800 - Train Loss = 0.39746993958950044
Epoch: 14, Batch Index: 2820 - Train Loss = 0.3977667087316513
Epoch: 14, Batch Index: 2840 - Train Loss = 0.39638291656970975
Epoch: 14, Batch Index: 2860 - Train Loss = 0.3958066064119339
Epoch: 14, Batch Index: 2880 - Train Loss = 0.39620551466941833
Epoch: 14, Batch Index: 2900 - Train Loss = 0.39700751841068266
Epoch: 14, Batch Index: 2920 - Train Loss = 0.39792332887649534
Epoch: 14, Batch Index: 2940 - Train Loss = 0.3981608068943024
Epoch: 14, Batch Index: 2960 - Train Loss = 0.3968786609172821
Epoch: 14, Batch Index: 2980 - Train Loss = 0.39690771281719206
Starting Epoch Index 15
Evaluating train set
Epoch: 15, Batch Index: 3000- Eval train - q_loss = 0.39590 , q_risk_0.1 = 0.22212 , q_risk_0.5 = 0.53453 , q_risk_0.9 = 0.23504
Evaluating validation set
Epoch: 15, Batch Index: 3000- Eval validation - q_loss = 0.37228 , q_risk_0.1 = 0.19195 , q_risk_0.5 = 0.50551 , q_risk_0.9 = 0.23166
Evaluating test set
Epoch: 15, Batch Index: 3000- Eval test - q_loss = 0.40615 , q_risk_0.1 = 0.22639 , q_risk_0.5 = 0.55196 , q_risk_0.9 = 0.24593
Epoch: 15, Batch Index: 3000 - Train Loss = 0.39571544885635374
Epoch: 15, Batch Index: 3020 - Train Loss = 0.3961531764268875
Epoch: 15, Batch Index: 3040 - Train Loss = 0.39620076477527616
Epoch: 15, Batch Index: 3060 - Train Loss = 0.3955254822969437
Epoch: 15, Batch Index: 3080 - Train Loss = 0.3957783627510071
Epoch: 15, Batch Index: 3100 - Train Loss = 0.39409859240055084
Epoch: 15, Batch Index: 3120 - Train Loss = 0.394546263217926
Epoch: 15, Batch Index: 3140 - Train Loss = 0.3941196483373642
Epoch: 15, Batch Index: 3160 - Train Loss = 0.3953500097990036
Epoch: 15, Batch Index: 3180 - Train Loss = 0.39435318410396575
Starting Epoch Index 16
Evaluating train set
Epoch: 16, Batch Index: 3200- Eval train - q_loss = 0.39311 , q_risk_0.1 = 0.22106 , q_risk_0.5 = 0.53087 , q_risk_0.9 = 0.23375
Evaluating validation set
Epoch: 16, Batch Index: 3200- Eval validation - q_loss = 0.36995 , q_risk_0.1 = 0.19182 , q_risk_0.5 = 0.50196 , q_risk_0.9 = 0.23022
Evaluating test set
Epoch: 16, Batch Index: 3200- Eval test - q_loss = 0.40404 , q_risk_0.1 = 0.22498 , q_risk_0.5 = 0.54958 , q_risk_0.9 = 0.24624
Epoch: 16, Batch Index: 3200 - Train Loss = 0.39327936828136445
Epoch: 16, Batch Index: 3220 - Train Loss = 0.39240858078002927
Epoch: 16, Batch Index: 3240 - Train Loss = 0.39418687641620637
Epoch: 16, Batch Index: 3260 - Train Loss = 0.3960178005695343
Epoch: 16, Batch Index: 3280 - Train Loss = 0.39683654487133024
Epoch: 16, Batch Index: 3300 - Train Loss = 0.3963241118192673
Epoch: 16, Batch Index: 3320 - Train Loss = 0.39427025318145753
Epoch: 16, Batch Index: 3340 - Train Loss = 0.39327972531318667
Epoch: 16, Batch Index: 3360 - Train Loss = 0.39355730831623076
Epoch: 16, Batch Index: 3380 - Train Loss = 0.3935112875699997
Starting Epoch Index 17
Evaluating train set
Epoch: 17, Batch Index: 3400- Eval train - q_loss = 0.39267 , q_risk_0.1 = 0.21894 , q_risk_0.5 = 0.52937 , q_risk_0.9 = 0.23373
Evaluating validation set
Epoch: 17, Batch Index: 3400- Eval validation - q_loss = 0.36965 , q_risk_0.1 = 0.18946 , q_risk_0.5 = 0.50238 , q_risk_0.9 = 0.23064
Evaluating test set
Epoch: 17, Batch Index: 3400- Eval test - q_loss = 0.40385 , q_risk_0.1 = 0.22403 , q_risk_0.5 = 0.55088 , q_risk_0.9 = 0.24741
Epoch: 17, Batch Index: 3400 - Train Loss = 0.3934555548429489
Epoch: 17, Batch Index: 3420 - Train Loss = 0.39430442929267884
Epoch: 17, Batch Index: 3440 - Train Loss = 0.394860475063324
Epoch: 17, Batch Index: 3460 - Train Loss = 0.3947139686346054
Epoch: 17, Batch Index: 3480 - Train Loss = 0.3969425678253174
Epoch: 17, Batch Index: 3500 - Train Loss = 0.39629222512245177
Epoch: 17, Batch Index: 3520 - Train Loss = 0.39453535914421084
Epoch: 17, Batch Index: 3540 - Train Loss = 0.39338121831417083
Epoch: 17, Batch Index: 3560 - Train Loss = 0.39583060920238494
Epoch: 17, Batch Index: 3580 - Train Loss = 0.3953281724452972
Starting Epoch Index 18
Evaluating train set
Epoch: 18, Batch Index: 3600- Eval train - q_loss = 0.39411 , q_risk_0.1 = 0.22071 , q_risk_0.5 = 0.53185 , q_risk_0.9 = 0.23386
Evaluating validation set
Epoch: 18, Batch Index: 3600- Eval validation - q_loss = 0.37043 , q_risk_0.1 = 0.19030 , q_risk_0.5 = 0.50372 , q_risk_0.9 = 0.23137
Evaluating test set
Epoch: 18, Batch Index: 3600- Eval test - q_loss = 0.40424 , q_risk_0.1 = 0.22493 , q_risk_0.5 = 0.54978 , q_risk_0.9 = 0.24472
Epoch: 18, Batch Index: 3600 - Train Loss = 0.3962299686670303
Epoch: 18, Batch Index: 3620 - Train Loss = 0.3964512723684311
Epoch: 18, Batch Index: 3640 - Train Loss = 0.39531580328941346
Epoch: 18, Batch Index: 3660 - Train Loss = 0.3951317095756531
Epoch: 18, Batch Index: 3680 - Train Loss = 0.39483638882637023
Epoch: 18, Batch Index: 3700 - Train Loss = 0.39424086570739747
Epoch: 18, Batch Index: 3720 - Train Loss = 0.3934622985124588
Epoch: 18, Batch Index: 3740 - Train Loss = 0.39204382538795474
Epoch: 18, Batch Index: 3760 - Train Loss = 0.39244626939296723
Epoch: 18, Batch Index: 3780 - Train Loss = 0.39162741959095
Starting Epoch Index 19
Evaluating train set
Epoch: 19, Batch Index: 3800- Eval train - q_loss = 0.39236 , q_risk_0.1 = 0.21986 , q_risk_0.5 = 0.53063 , q_risk_0.9 = 0.23303
Evaluating validation set
Epoch: 19, Batch Index: 3800- Eval validation - q_loss = 0.36917 , q_risk_0.1 = 0.19038 , q_risk_0.5 = 0.50183 , q_risk_0.9 = 0.23023
Evaluating test set
Epoch: 19, Batch Index: 3800- Eval test - q_loss = 0.40360 , q_risk_0.1 = 0.22352 , q_risk_0.5 = 0.54832 , q_risk_0.9 = 0.24480
Epoch: 19, Batch Index: 3800 - Train Loss = 0.39128984570503234
Epoch: 19, Batch Index: 3820 - Train Loss = 0.3910816216468811
Epoch: 19, Batch Index: 3840 - Train Loss = 0.3931230807304382
Epoch: 19, Batch Index: 3860 - Train Loss = 0.39342101812362673
Epoch: 19, Batch Index: 3880 - Train Loss = 0.39307539820671084
Epoch: 19, Batch Index: 3900 - Train Loss = 0.39352298736572267
Epoch: 19, Batch Index: 3920 - Train Loss = 0.39266403555870055
Epoch: 19, Batch Index: 3940 - Train Loss = 0.39387556493282316
Epoch: 19, Batch Index: 3960 - Train Loss = 0.3941167360544205
Epoch: 19, Batch Index: 3980 - Train Loss = 0.3933072590827942
Starting Epoch Index 20
Evaluating train set
Epoch: 20, Batch Index: 4000- Eval train - q_loss = 0.39171 , q_risk_0.1 = 0.21977 , q_risk_0.5 = 0.52934 , q_risk_0.9 = 0.23252
Evaluating validation set
Epoch: 20, Batch Index: 4000- Eval validation - q_loss = 0.36842 , q_risk_0.1 = 0.18975 , q_risk_0.5 = 0.49880 , q_risk_0.9 = 0.22967
Evaluating test set
Epoch: 20, Batch Index: 4000- Eval test - q_loss = 0.40268 , q_risk_0.1 = 0.22340 , q_risk_0.5 = 0.54762 , q_risk_0.9 = 0.24478
Epoch: 20, Batch Index: 4000 - Train Loss = 0.3935540908575058
Epoch: 20, Batch Index: 4020 - Train Loss = 0.3945341455936432
Epoch: 20, Batch Index: 4040 - Train Loss = 0.3948543339967728
Epoch: 20, Batch Index: 4060 - Train Loss = 0.39625866651535036
Epoch: 20, Batch Index: 4080 - Train Loss = 0.3947367179393768
Epoch: 20, Batch Index: 4100 - Train Loss = 0.3921550667285919
Epoch: 20, Batch Index: 4120 - Train Loss = 0.3913376384973526
Epoch: 20, Batch Index: 4140 - Train Loss = 0.3914654874801636
Epoch: 20, Batch Index: 4160 - Train Loss = 0.392972172498703
Epoch: 20, Batch Index: 4180 - Train Loss = 0.3916538977622986
Starting Epoch Index 21
Evaluating train set
Epoch: 21, Batch Index: 4200- Eval train - q_loss = 0.39359 , q_risk_0.1 = 0.21875 , q_risk_0.5 = 0.53450 , q_risk_0.9 = 0.23349
Evaluating validation set
Epoch: 21, Batch Index: 4200- Eval validation - q_loss = 0.36954 , q_risk_0.1 = 0.18822 , q_risk_0.5 = 0.50501 , q_risk_0.9 = 0.23005
Evaluating test set
Epoch: 21, Batch Index: 4200- Eval test - q_loss = 0.40425 , q_risk_0.1 = 0.22260 , q_risk_0.5 = 0.55251 , q_risk_0.9 = 0.24582
Epoch: 21, Batch Index: 4200 - Train Loss = 0.39065551578998564
Epoch: 21, Batch Index: 4220 - Train Loss = 0.3920184302330017
Epoch: 21, Batch Index: 4240 - Train Loss = 0.39294574737548826
Epoch: 21, Batch Index: 4260 - Train Loss = 0.3921638345718384
Epoch: 21, Batch Index: 4280 - Train Loss = 0.39221913754940035
Epoch: 21, Batch Index: 4300 - Train Loss = 0.39228733897209167
Epoch: 21, Batch Index: 4320 - Train Loss = 0.39290284991264346
Epoch: 21, Batch Index: 4340 - Train Loss = 0.39263272523880005
Epoch: 21, Batch Index: 4360 - Train Loss = 0.39253047585487366
Epoch: 21, Batch Index: 4380 - Train Loss = 0.39298843801021577
Starting Epoch Index 22
Evaluating train set
Epoch: 22, Batch Index: 4400- Eval train - q_loss = 0.39157 , q_risk_0.1 = 0.21867 , q_risk_0.5 = 0.53062 , q_risk_0.9 = 0.23265
Evaluating validation set
Epoch: 22, Batch Index: 4400- Eval validation - q_loss = 0.36894 , q_risk_0.1 = 0.18825 , q_risk_0.5 = 0.50249 , q_risk_0.9 = 0.23015
Evaluating test set
Epoch: 22, Batch Index: 4400- Eval test - q_loss = 0.40272 , q_risk_0.1 = 0.22289 , q_risk_0.5 = 0.55017 , q_risk_0.9 = 0.24553
Epoch: 22, Batch Index: 4400 - Train Loss = 0.3928170812129974
Epoch: 22, Batch Index: 4420 - Train Loss = 0.39240060448646547
Epoch: 22, Batch Index: 4440 - Train Loss = 0.39123848140239714
Epoch: 22, Batch Index: 4460 - Train Loss = 0.39128577649593355
Epoch: 22, Batch Index: 4480 - Train Loss = 0.39194220066070556
Epoch: 22, Batch Index: 4500 - Train Loss = 0.3927388870716095
Epoch: 22, Batch Index: 4520 - Train Loss = 0.3947614371776581
Epoch: 22, Batch Index: 4540 - Train Loss = 0.39322260677814486
Epoch: 22, Batch Index: 4560 - Train Loss = 0.3928615152835846
Epoch: 22, Batch Index: 4580 - Train Loss = 0.3923887598514557
Starting Epoch Index 23
Evaluating train set
Epoch: 23, Batch Index: 4600- Eval train - q_loss = 0.39578 , q_risk_0.1 = 0.21877 , q_risk_0.5 = 0.53504 , q_risk_0.9 = 0.23619
Evaluating validation set
Epoch: 23, Batch Index: 4600- Eval validation - q_loss = 0.37264 , q_risk_0.1 = 0.18828 , q_risk_0.5 = 0.50772 , q_risk_0.9 = 0.23416
Evaluating test set
Epoch: 23, Batch Index: 4600- Eval test - q_loss = 0.40778 , q_risk_0.1 = 0.22321 , q_risk_0.5 = 0.55644 , q_risk_0.9 = 0.25071
Epoch: 23, Batch Index: 4600 - Train Loss = 0.3926751935482025
Epoch: 23, Batch Index: 4620 - Train Loss = 0.3935908442735672
Epoch: 23, Batch Index: 4640 - Train Loss = 0.392884778380394
Epoch: 23, Batch Index: 4660 - Train Loss = 0.3941209644079208
Epoch: 23, Batch Index: 4680 - Train Loss = 0.39364977955818176
Epoch: 23, Batch Index: 4700 - Train Loss = 0.39289494812488557
Epoch: 23, Batch Index: 4720 - Train Loss = 0.3917523670196533
Epoch: 23, Batch Index: 4740 - Train Loss = 0.39211202681064605
Epoch: 23, Batch Index: 4760 - Train Loss = 0.3919273245334625
Epoch: 23, Batch Index: 4780 - Train Loss = 0.39112240612506866
Starting Epoch Index 24
Evaluating train set
Epoch: 24, Batch Index: 4800- Eval train - q_loss = 0.39073 , q_risk_0.1 = 0.21867 , q_risk_0.5 = 0.52852 , q_risk_0.9 = 0.23234
Evaluating validation set
Epoch: 24, Batch Index: 4800- Eval validation - q_loss = 0.36755 , q_risk_0.1 = 0.18810 , q_risk_0.5 = 0.49981 , q_risk_0.9 = 0.22989
Evaluating test set
Epoch: 24, Batch Index: 4800- Eval test - q_loss = 0.40219 , q_risk_0.1 = 0.22368 , q_risk_0.5 = 0.54789 , q_risk_0.9 = 0.24424
Epoch: 24, Batch Index: 4800 - Train Loss = 0.39104080975055694
Epoch: 24, Batch Index: 4820 - Train Loss = 0.3915447109937668
Epoch: 24, Batch Index: 4840 - Train Loss = 0.39162757694721223
Epoch: 24, Batch Index: 4860 - Train Loss = 0.391264573931694
Epoch: 24, Batch Index: 4880 - Train Loss = 0.3915964841842651
Epoch: 24, Batch Index: 4900 - Train Loss = 0.392146959900856
Epoch: 24, Batch Index: 4920 - Train Loss = 0.39214262783527376
Epoch: 24, Batch Index: 4940 - Train Loss = 0.3912676954269409
Epoch: 24, Batch Index: 4960 - Train Loss = 0.390901859998703
Epoch: 24, Batch Index: 4980 - Train Loss = 0.3914948982000351
Starting Epoch Index 25
Evaluating train set
Epoch: 25, Batch Index: 5000- Eval train - q_loss = 0.39103 , q_risk_0.1 = 0.21824 , q_risk_0.5 = 0.52878 , q_risk_0.9 = 0.23258
Evaluating validation set
Epoch: 25, Batch Index: 5000- Eval validation - q_loss = 0.36727 , q_risk_0.1 = 0.18754 , q_risk_0.5 = 0.49930 , q_risk_0.9 = 0.22967
Evaluating test set
Epoch: 25, Batch Index: 5000- Eval test - q_loss = 0.40200 , q_risk_0.1 = 0.22221 , q_risk_0.5 = 0.54803 , q_risk_0.9 = 0.24508
Epoch: 25, Batch Index: 5000 - Train Loss = 0.39295695662498475
Epoch: 25, Batch Index: 5020 - Train Loss = 0.3930238527059555
Epoch: 25, Batch Index: 5040 - Train Loss = 0.39276827991008756
Epoch: 25, Batch Index: 5060 - Train Loss = 0.39349680066108705
Epoch: 25, Batch Index: 5080 - Train Loss = 0.39223547756671906
Epoch: 25, Batch Index: 5100 - Train Loss = 0.39093770444393156
Epoch: 25, Batch Index: 5120 - Train Loss = 0.3900302243232727
Epoch: 25, Batch Index: 5140 - Train Loss = 0.3915100681781769
Epoch: 25, Batch Index: 5160 - Train Loss = 0.39345851361751555
Epoch: 25, Batch Index: 5180 - Train Loss = 0.39556327760219573
Starting Epoch Index 26
Evaluating train set
Epoch: 26, Batch Index: 5200- Eval train - q_loss = 0.39117 , q_risk_0.1 = 0.21851 , q_risk_0.5 = 0.52961 , q_risk_0.9 = 0.23249
Evaluating validation set
Epoch: 26, Batch Index: 5200- Eval validation - q_loss = 0.36806 , q_risk_0.1 = 0.18893 , q_risk_0.5 = 0.50076 , q_risk_0.9 = 0.22973
Evaluating test set
Epoch: 26, Batch Index: 5200- Eval test - q_loss = 0.40395 , q_risk_0.1 = 0.22472 , q_risk_0.5 = 0.54988 , q_risk_0.9 = 0.24445
Epoch: 26, Batch Index: 5200 - Train Loss = 0.39528673231601713
Epoch: 26, Batch Index: 5220 - Train Loss = 0.3938353776931763
Epoch: 26, Batch Index: 5240 - Train Loss = 0.3929093545675278
Epoch: 26, Batch Index: 5260 - Train Loss = 0.393796883225441
Epoch: 26, Batch Index: 5280 - Train Loss = 0.3937105721235275
Epoch: 26, Batch Index: 5300 - Train Loss = 0.3911102694272995
Epoch: 26, Batch Index: 5320 - Train Loss = 0.39100204229354857
Epoch: 26, Batch Index: 5340 - Train Loss = 0.3912016826868057
Epoch: 26, Batch Index: 5360 - Train Loss = 0.3917206537723541
Epoch: 26, Batch Index: 5380 - Train Loss = 0.39080328583717344
Starting Epoch Index 27
Evaluating train set
Epoch: 27, Batch Index: 5400- Eval train - q_loss = 0.39265 , q_risk_0.1 = 0.21775 , q_risk_0.5 = 0.53054 , q_risk_0.9 = 0.23295
Evaluating validation set
Epoch: 27, Batch Index: 5400- Eval validation - q_loss = 0.37037 , q_risk_0.1 = 0.18791 , q_risk_0.5 = 0.50539 , q_risk_0.9 = 0.23140
Evaluating test set
Epoch: 27, Batch Index: 5400- Eval test - q_loss = 0.40449 , q_risk_0.1 = 0.22310 , q_risk_0.5 = 0.55233 , q_risk_0.9 = 0.24602
Epoch: 27, Batch Index: 5400 - Train Loss = 0.3907390028238297
Epoch: 27, Batch Index: 5420 - Train Loss = 0.391916623711586
Epoch: 27, Batch Index: 5440 - Train Loss = 0.39387652039527893
Epoch: 27, Batch Index: 5460 - Train Loss = 0.3932059967517853
Epoch: 27, Batch Index: 5480 - Train Loss = 0.39354217767715455
Epoch: 27, Batch Index: 5500 - Train Loss = 0.3938298052549362
Epoch: 27, Batch Index: 5520 - Train Loss = 0.39483376502990725
Epoch: 27, Batch Index: 5540 - Train Loss = 0.39367376029491424
Epoch: 27, Batch Index: 5560 - Train Loss = 0.39227177858352663
Epoch: 27, Batch Index: 5580 - Train Loss = 0.3912710964679718
Starting Epoch Index 28
Evaluating train set
Epoch: 28, Batch Index: 5600- Eval train - q_loss = 0.39010 , q_risk_0.1 = 0.21711 , q_risk_0.5 = 0.52652 , q_risk_0.9 = 0.23247
Evaluating validation set
Epoch: 28, Batch Index: 5600- Eval validation - q_loss = 0.36690 , q_risk_0.1 = 0.18706 , q_risk_0.5 = 0.49793 , q_risk_0.9 = 0.22968
Evaluating test set
Epoch: 28, Batch Index: 5600- Eval test - q_loss = 0.40209 , q_risk_0.1 = 0.22186 , q_risk_0.5 = 0.54638 , q_risk_0.9 = 0.24374
Epoch: 28, Batch Index: 5600 - Train Loss = 0.39116894245147704
Epoch: 28, Batch Index: 5620 - Train Loss = 0.39049896657466887
Epoch: 28, Batch Index: 5640 - Train Loss = 0.39136357307434083
Epoch: 28, Batch Index: 5660 - Train Loss = 0.3927433145046234
Epoch: 28, Batch Index: 5680 - Train Loss = 0.3914398127794266
Epoch: 28, Batch Index: 5700 - Train Loss = 0.3910479825735092
Epoch: 28, Batch Index: 5720 - Train Loss = 0.39200413167476655
Epoch: 28, Batch Index: 5740 - Train Loss = 0.3924363601207733
Epoch: 28, Batch Index: 5760 - Train Loss = 0.3915549123287201
Epoch: 28, Batch Index: 5780 - Train Loss = 0.3906639659404755
Starting Epoch Index 29
Evaluating train set
Epoch: 29, Batch Index: 5800- Eval train - q_loss = 0.39020 , q_risk_0.1 = 0.21734 , q_risk_0.5 = 0.52575 , q_risk_0.9 = 0.23267
Evaluating validation set
Epoch: 29, Batch Index: 5800- Eval validation - q_loss = 0.36615 , q_risk_0.1 = 0.18721 , q_risk_0.5 = 0.49772 , q_risk_0.9 = 0.22981
Evaluating test set
Epoch: 29, Batch Index: 5800- Eval test - q_loss = 0.40220 , q_risk_0.1 = 0.22248 , q_risk_0.5 = 0.54862 , q_risk_0.9 = 0.24761
Epoch: 29, Batch Index: 5800 - Train Loss = 0.39212010741233827
Epoch: 29, Batch Index: 5820 - Train Loss = 0.39072294294834137
Epoch: 29, Batch Index: 5840 - Train Loss = 0.39052855253219604
Epoch: 29, Batch Index: 5860 - Train Loss = 0.39218976140022277
Epoch: 29, Batch Index: 5880 - Train Loss = 0.3931941443681717
Epoch: 29, Batch Index: 5900 - Train Loss = 0.393218988776207
Epoch: 29, Batch Index: 5920 - Train Loss = 0.39163510739803314
Epoch: 29, Batch Index: 5940 - Train Loss = 0.3915703827142715
Epoch: 29, Batch Index: 5960 - Train Loss = 0.3931459194421768
Epoch: 29, Batch Index: 5980 - Train Loss = 0.3931496340036392
Starting Epoch Index 30
Evaluating train set
Epoch: 30, Batch Index: 6000- Eval train - q_loss = 0.39057 , q_risk_0.1 = 0.21825 , q_risk_0.5 = 0.52727 , q_risk_0.9 = 0.23261
Evaluating validation set
Epoch: 30, Batch Index: 6000- Eval validation - q_loss = 0.36738 , q_risk_0.1 = 0.18919 , q_risk_0.5 = 0.49924 , q_risk_0.9 = 0.22976
Evaluating test set
Epoch: 30, Batch Index: 6000- Eval test - q_loss = 0.40191 , q_risk_0.1 = 0.22286 , q_risk_0.5 = 0.54679 , q_risk_0.9 = 0.24536
Epoch: 30, Batch Index: 6000 - Train Loss = 0.3902744472026825
Epoch: 30, Batch Index: 6020 - Train Loss = 0.3907164472341538
Epoch: 30, Batch Index: 6040 - Train Loss = 0.39019503772258757
Epoch: 30, Batch Index: 6060 - Train Loss = 0.3909304445981979
Epoch: 30, Batch Index: 6080 - Train Loss = 0.3915932935476303
Epoch: 30, Batch Index: 6100 - Train Loss = 0.3912838155031204
Epoch: 30, Batch Index: 6120 - Train Loss = 0.39170918226242063
Epoch: 30, Batch Index: 6140 - Train Loss = 0.3924876689910889
Epoch: 30, Batch Index: 6160 - Train Loss = 0.39197428166866305
Epoch: 30, Batch Index: 6180 - Train Loss = 0.3910445886850357
Starting Epoch Index 31
Evaluating train set
Epoch: 31, Batch Index: 6200- Eval train - q_loss = 0.38975 , q_risk_0.1 = 0.21851 , q_risk_0.5 = 0.52767 , q_risk_0.9 = 0.23239
Evaluating validation set
Epoch: 31, Batch Index: 6200- Eval validation - q_loss = 0.36598 , q_risk_0.1 = 0.18756 , q_risk_0.5 = 0.49667 , q_risk_0.9 = 0.22891
Evaluating test set
Epoch: 31, Batch Index: 6200- Eval test - q_loss = 0.40154 , q_risk_0.1 = 0.22225 , q_risk_0.5 = 0.54562 , q_risk_0.9 = 0.24451
Epoch: 31, Batch Index: 6200 - Train Loss = 0.3908955878019333
Epoch: 31, Batch Index: 6220 - Train Loss = 0.3918736004829407
Epoch: 31, Batch Index: 6240 - Train Loss = 0.39150700986385345
Epoch: 31, Batch Index: 6260 - Train Loss = 0.39203780233860014
Epoch: 31, Batch Index: 6280 - Train Loss = 0.3901748996973038
Epoch: 31, Batch Index: 6300 - Train Loss = 0.38915141344070436
Epoch: 31, Batch Index: 6320 - Train Loss = 0.39070659518241885
Epoch: 31, Batch Index: 6340 - Train Loss = 0.3905073881149292
Epoch: 31, Batch Index: 6360 - Train Loss = 0.3902280455827713
Epoch: 31, Batch Index: 6380 - Train Loss = 0.3916871452331543
Starting Epoch Index 32
Evaluating train set
Epoch: 32, Batch Index: 6400- Eval train - q_loss = 0.38995 , q_risk_0.1 = 0.21762 , q_risk_0.5 = 0.52858 , q_risk_0.9 = 0.23154
Evaluating validation set
Epoch: 32, Batch Index: 6400- Eval validation - q_loss = 0.36668 , q_risk_0.1 = 0.18702 , q_risk_0.5 = 0.49939 , q_risk_0.9 = 0.22871
Evaluating test set
Epoch: 32, Batch Index: 6400- Eval test - q_loss = 0.40167 , q_risk_0.1 = 0.22138 , q_risk_0.5 = 0.54762 , q_risk_0.9 = 0.24413
Epoch: 32, Batch Index: 6400 - Train Loss = 0.39202110826969144
Epoch: 32, Batch Index: 6420 - Train Loss = 0.39096222519874574
Epoch: 32, Batch Index: 6440 - Train Loss = 0.39030987441539766
Epoch: 32, Batch Index: 6460 - Train Loss = 0.3898254519701004
Epoch: 32, Batch Index: 6480 - Train Loss = 0.39056360721588135
Epoch: 32, Batch Index: 6500 - Train Loss = 0.39097073435783386
Epoch: 32, Batch Index: 6520 - Train Loss = 0.3911157739162445
Epoch: 32, Batch Index: 6540 - Train Loss = 0.391190242767334
Epoch: 32, Batch Index: 6560 - Train Loss = 0.39081517279148104
Epoch: 32, Batch Index: 6580 - Train Loss = 0.38984852373600004
Starting Epoch Index 33
Evaluating train set
Epoch: 33, Batch Index: 6600- Eval train - q_loss = 0.38943 , q_risk_0.1 = 0.21677 , q_risk_0.5 = 0.52403 , q_risk_0.9 = 0.23132
Evaluating validation set
Epoch: 33, Batch Index: 6600- Eval validation - q_loss = 0.36607 , q_risk_0.1 = 0.18704 , q_risk_0.5 = 0.49742 , q_risk_0.9 = 0.22981
Evaluating test set
Epoch: 33, Batch Index: 6600- Eval test - q_loss = 0.40122 , q_risk_0.1 = 0.22210 , q_risk_0.5 = 0.54654 , q_risk_0.9 = 0.24553
Epoch: 33, Batch Index: 6600 - Train Loss = 0.39000167965888977
Epoch: 33, Batch Index: 6620 - Train Loss = 0.38943089842796325
Epoch: 33, Batch Index: 6640 - Train Loss = 0.39088996946811677
Epoch: 33, Batch Index: 6660 - Train Loss = 0.3900245302915573
Epoch: 33, Batch Index: 6680 - Train Loss = 0.3895224344730377
Epoch: 33, Batch Index: 6700 - Train Loss = 0.38981278002262115
Epoch: 33, Batch Index: 6720 - Train Loss = 0.38963438451290133
Epoch: 33, Batch Index: 6740 - Train Loss = 0.39057372629642484
Epoch: 33, Batch Index: 6760 - Train Loss = 0.3902643966674805
Epoch: 33, Batch Index: 6780 - Train Loss = 0.3898572677373886
Starting Epoch Index 34
Evaluating train set
Epoch: 34, Batch Index: 6800- Eval train - q_loss = 0.39050 , q_risk_0.1 = 0.21721 , q_risk_0.5 = 0.52811 , q_risk_0.9 = 0.23194
Evaluating validation set
Epoch: 34, Batch Index: 6800- Eval validation - q_loss = 0.36954 , q_risk_0.1 = 0.18786 , q_risk_0.5 = 0.50398 , q_risk_0.9 = 0.23089
Evaluating test set
Epoch: 34, Batch Index: 6800- Eval test - q_loss = 0.40233 , q_risk_0.1 = 0.22209 , q_risk_0.5 = 0.54882 , q_risk_0.9 = 0.24447
Epoch: 34, Batch Index: 6800 - Train Loss = 0.3901339966058731
Epoch: 34, Batch Index: 6820 - Train Loss = 0.390858815908432
Epoch: 34, Batch Index: 6840 - Train Loss = 0.3913135600090027
Epoch: 34, Batch Index: 6860 - Train Loss = 0.3918037086725235
Epoch: 34, Batch Index: 6880 - Train Loss = 0.3909101969003677
Epoch: 34, Batch Index: 6900 - Train Loss = 0.3903788596391678
Epoch: 34, Batch Index: 6920 - Train Loss = 0.3911781603097916
Epoch: 34, Batch Index: 6940 - Train Loss = 0.3906527698040009
Epoch: 34, Batch Index: 6960 - Train Loss = 0.39001287817955016
Epoch: 34, Batch Index: 6980 - Train Loss = 0.3880264741182327
Starting Epoch Index 35
Evaluating train set
Epoch: 35, Batch Index: 7000- Eval train - q_loss = 0.39028 , q_risk_0.1 = 0.22122 , q_risk_0.5 = 0.52642 , q_risk_0.9 = 0.23083
Evaluating validation set
Epoch: 35, Batch Index: 7000- Eval validation - q_loss = 0.36812 , q_risk_0.1 = 0.19225 , q_risk_0.5 = 0.49813 , q_risk_0.9 = 0.22896
Evaluating test set
Epoch: 35, Batch Index: 7000- Eval test - q_loss = 0.40325 , q_risk_0.1 = 0.22655 , q_risk_0.5 = 0.54788 , q_risk_0.9 = 0.24391
Epoch: 35, Batch Index: 7000 - Train Loss = 0.3893417567014694
Epoch: 35, Batch Index: 7020 - Train Loss = 0.39094632387161254
Epoch: 35, Batch Index: 7040 - Train Loss = 0.3901081711053848
Epoch: 35, Batch Index: 7060 - Train Loss = 0.3909002935886383
Epoch: 35, Batch Index: 7080 - Train Loss = 0.38972910821437834
Epoch: 35, Batch Index: 7100 - Train Loss = 0.39056070685386657
Epoch: 35, Batch Index: 7120 - Train Loss = 0.3917739289999008
Epoch: 35, Batch Index: 7140 - Train Loss = 0.39201636493206027
Epoch: 35, Batch Index: 7160 - Train Loss = 0.39356399834156036
Epoch: 35, Batch Index: 7180 - Train Loss = 0.3922375839948654
Starting Epoch Index 36
Evaluating train set
Epoch: 36, Batch Index: 7200- Eval train - q_loss = 0.38957 , q_risk_0.1 = 0.21744 , q_risk_0.5 = 0.52563 , q_risk_0.9 = 0.23092
Evaluating validation set
Epoch: 36, Batch Index: 7200- Eval validation - q_loss = 0.36618 , q_risk_0.1 = 0.18797 , q_risk_0.5 = 0.49785 , q_risk_0.9 = 0.22884
Evaluating test set
Epoch: 36, Batch Index: 7200- Eval test - q_loss = 0.40127 , q_risk_0.1 = 0.22190 , q_risk_0.5 = 0.54540 , q_risk_0.9 = 0.24297
Performing early stopping...!
</pre></div></div>
</div>
</div>
</div>
<div class="section" id="Explore-Model-Outputs">
<h1>Explore Model Outputs<a class="headerlink" href="#Explore-Model-Outputs" title="Permalink to this headline">¶</a></h1>
<p>After training the model, we can use it and its outputs for a better understanding of its performance, and for trying to explain its estimations. That is what will be demonstrated in this tutorial, using the module <code class="docutils literal notranslate"><span class="pre">tft_torch.tft_vis</span></code>. We will rely on the dataset we produced on the dataset creation tutorial and on the model we trained in the model training tutorial.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[29]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">tft_torch.visualize</span> <span class="k">as</span> <span class="nn">tft_vis</span>
</pre></div>
</div>
</div>
<div class="section" id="Apply-the-model">
<h2>Apply the model<a class="headerlink" href="#Apply-the-model" title="Permalink to this headline">¶</a></h2>
<p>For collecting the outputs of the model, we’ll first run inference on the validation subset. Here we use the serial data loader assigned above:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[30]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span> <span class="c1"># switch to evaluation mode</span>

<span class="n">output_aggregator</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span> <span class="c1"># will be used for aggregating the outputs across batches</span>

<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="c1"># go over the batches of the serial data loader</span>
    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">validation_serial_loader</span><span class="p">):</span>
        <span class="c1"># process each batch</span>
        <span class="k">if</span> <span class="n">is_cuda</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">batch</span><span class="o">.</span><span class="n">keys</span><span class="p">()):</span>
                <span class="n">batch</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">batch_outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>

        <span class="c1"># accumulate outputs, as well as labels</span>
        <span class="k">for</span> <span class="n">output_key</span><span class="p">,</span><span class="n">output_tensor</span> <span class="ow">in</span> <span class="n">batch_outputs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">output_aggregator</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="n">output_key</span><span class="p">,[])</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output_tensor</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
        <span class="n">output_aggregator</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s1">&#39;target&#39;</span><span class="p">,[])</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
100%|██████████| 30/30 [00:10&lt;00:00,  2.74it/s]
</pre></div></div>
</div>
<p>and then stack the outpus from all the batches:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[31]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">validation_outputs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">output_aggregator</span><span class="o">.</span><span class="n">keys</span><span class="p">()):</span>
    <span class="n">validation_outputs</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">output_aggregator</span><span class="p">[</span><span class="n">k</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Let’s say the subset we’re working with includes <span class="math notranslate nohighlight">\(N\)</span> observations, and each observation consists of:</p>
<ul class="simple">
<li><p>a historical time-series that includes <span class="math notranslate nohighlight">\(m_{historical}\)</span> temporal variables, spanning <span class="math notranslate nohighlight">\(T_{past}\)</span> past time-steps.</p></li>
<li><p>a <em>futuristic</em> time-series including <span class="math notranslate nohighlight">\(m_{future}\)</span> temporal variables, spanning <span class="math notranslate nohighlight">\(T_{fut}\)</span> futuristic time-steps.</p></li>
<li><p>a set of <span class="math notranslate nohighlight">\(m_{static}\)</span> static variables.</p></li>
</ul>
<p>In addition, let’s assume that the model is configured to estimate <span class="math notranslate nohighlight">\(d_q\)</span> different quantiles.</p>
<p>In such case the outputs of the model will be as follows:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">predicted_quantiles</span></code> - the model quantile estimates for each temporal future step, shaped as <span class="math notranslate nohighlight">\([N \times T_{fut} \times d_q]\)</span>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">static_weights</span></code> - the selection weights associated with the static variables for each observation, shaped as <span class="math notranslate nohighlight">\([N \times m_{static}]\)</span>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">historical_selection_weights</span></code> - the selection weights associated with the historical temporal variables, for each observation, and past time-step, shaped as <span class="math notranslate nohighlight">\([N \times T_{past} \times m_{historical}]\)</span>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">future_selection_weights</span></code> - the selection weights associated with the future temporal variables, for each observation, and future time-step, shaped as <span class="math notranslate nohighlight">\([N \times T_{fut} \times m_{future}]\)</span>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">attention_scores</span></code> - the attention score each future time-step associates which each other time-step, for each observation, shaped as <span class="math notranslate nohighlight">\([N \times T_{fut} \times (T_{past} + T_{fut})]\)</span>.</p></li>
</ul>
<p>Some of the illustrations below will refer to a single observation (sample-level), and some will perform aggregation of the outputs for the entire subset data. For that matter, we’ll arbitrarily set an index indicating the sample/record that will be used for the demonstration of the sample-level illustrations:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[32]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">chosen_idx</span> <span class="o">=</span> <span class="mi">42421</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Target-Signal-Trajectory">
<h2>Target Signal Trajectory<a class="headerlink" href="#Target-Signal-Trajectory" title="Permalink to this headline">¶</a></h2>
<p>On this section we’ll extract the historical sequence associated with the target variable, for the specific observation chosen, together with the futuristic label (the future target), and the predicted quantiles output by the model.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[33]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># the name of the target signal</span>
<span class="n">target_signal</span> <span class="o">=</span> <span class="s1">&#39;log_sales&#39;</span>
<span class="c1"># its relative index among the set of historical numeric input variables</span>
<span class="n">target_var_index</span> <span class="o">=</span> <span class="n">feature_map</span><span class="p">[</span><span class="s1">&#39;historical_ts_numeric&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">target_signal</span><span class="p">)</span>
<span class="c1"># the quantiles estimated by the trained model</span>
<span class="n">model_quantiles</span> <span class="o">=</span> <span class="n">configuration</span><span class="p">[</span><span class="s1">&#39;model&#39;</span><span class="p">][</span><span class="s1">&#39;output_quantiles&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<p>The trajectory can be viewed in two different scales: Our first view will refer to the normalized scale. Recall that before feeding the data to the model, all of our input variables were scaled or encoded. because the target signal was scaled as well, the outputs of the model are also designated to estimate the target signal according to this “<em>new</em>” normalized scale.</p>
<p>In the follwing chart we can see: - on the left: the historical values of the target variable. - dashed line separating past and future. - on the right: (solid) future target variable - what the model aims to predict - on the right: (dashed) dashed lines associated with the predicted quantiles (see legend) - on the right: a colored sleeve between and the lower and upper quantiles; can be seen as the uncertainty sleeve for each horizon.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[51]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">tft_vis</span><span class="o">.</span><span class="n">display_target_trajectory</span><span class="p">(</span><span class="n">signal_history</span><span class="o">=</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;data_sets&#39;</span><span class="p">][</span><span class="s1">&#39;validation&#39;</span><span class="p">][</span><span class="s1">&#39;historical_ts_numeric&#39;</span><span class="p">][</span><span class="o">...</span><span class="p">,</span><span class="n">target_var_index</span><span class="p">],</span>
                                  <span class="n">signal_future</span><span class="o">=</span><span class="n">validation_outputs</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">],</span>
                                  <span class="n">model_preds</span><span class="o">=</span><span class="n">validation_outputs</span><span class="p">[</span><span class="s1">&#39;predicted_quantiles&#39;</span><span class="p">],</span>
                                  <span class="n">observation_index</span><span class="o">=</span><span class="n">chosen_idx</span><span class="p">,</span>
                                  <span class="n">model_quantiles</span><span class="o">=</span><span class="n">model_quantiles</span><span class="p">,</span>
                                  <span class="n">unit</span><span class="o">=</span><span class="s1">&#39;Days&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorials_TrainingExample_70_0.png" src="../_images/tutorials_TrainingExample_70_0.png" />
</div>
</div>
<p>However, in some cases we would like to observe the actual scale of the target variable. For that matter, the method we’re using, <code class="docutils literal notranslate"><span class="pre">tft_vis.display_target_trajectory()</span></code> optionally accepts also the input argument <code class="docutils literal notranslate"><span class="pre">transformation</span></code> , which can be used for scaling back the target variable to its original scale.</p>
<p>In our use case, the target variable went through a log-transform (<span class="math notranslate nohighlight">\(log_{10}(1+x)\)</span>), and then scaled using the scaler we saved along with the data. We use this to formulate the inverse scaling, and <em>send</em> this transformation to the visualization utility.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[52]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">scale_back</span><span class="p">(</span><span class="n">scaler_obj</span><span class="p">,</span><span class="n">signal</span><span class="p">):</span>
    <span class="n">inv_trans</span> <span class="o">=</span> <span class="n">scaler_obj</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">signal</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="n">inv_trans</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
<span class="n">transform_back</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">scale_back</span><span class="p">,</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;scalers&#39;</span><span class="p">][</span><span class="s1">&#39;numeric&#39;</span><span class="p">][</span><span class="n">target_signal</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[53]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">tft_vis</span><span class="o">.</span><span class="n">display_target_trajectory</span><span class="p">(</span><span class="n">signal_history</span><span class="o">=</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;data_sets&#39;</span><span class="p">][</span><span class="s1">&#39;validation&#39;</span><span class="p">][</span><span class="s1">&#39;historical_ts_numeric&#39;</span><span class="p">][</span><span class="o">...</span><span class="p">,</span><span class="n">target_var_index</span><span class="p">],</span>
                                  <span class="n">signal_future</span><span class="o">=</span><span class="n">validation_outputs</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">],</span>
                                  <span class="n">model_preds</span><span class="o">=</span><span class="n">validation_outputs</span><span class="p">[</span><span class="s1">&#39;predicted_quantiles&#39;</span><span class="p">],</span>
                                  <span class="n">observation_index</span><span class="o">=</span><span class="n">chosen_idx</span><span class="p">,</span>
                                  <span class="n">model_quantiles</span><span class="o">=</span><span class="n">model_quantiles</span><span class="p">,</span>
                                  <span class="n">unit</span><span class="o">=</span><span class="s1">&#39;Days&#39;</span><span class="p">,</span>
                                  <span class="n">transformation</span><span class="o">=</span><span class="n">transform_back</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorials_TrainingExample_73_0.png" src="../_images/tutorials_TrainingExample_73_0.png" />
</div>
</div>
<div class="section" id="Selection-Weights">
<h3>Selection Weights<a class="headerlink" href="#Selection-Weights" title="Permalink to this headline">¶</a></h3>
<p>The temporal fusion transformer model has an interntal mechanism for variable selection. Each input channel has a separate dedicated mechanism - historical temporal data, static descriptors data, known future inputs data. In the following section we’ll describe them visually.</p>
<p>Although the input to the model required us to split between the categorical variables and the numeric variables for each input channel, after the inputs are transformed upon feeding them to the model, the entire set of variables composing a single input channel (historical_ts / future_ts / static) are treated as one block, and the variable selection mechanism acts on them without any distinction.</p>
<p><strong>Note</strong>: in the suggested implementation, the numeric inputs are stacked first, before combining the categorical inputs (on each input channel separately). Hence, we conclude the complete set of input variables for each input channel as follows:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[37]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">static_feats</span> <span class="o">=</span> <span class="n">feature_map</span><span class="p">[</span><span class="s1">&#39;static_feats_numeric&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">feature_map</span><span class="p">[</span><span class="s1">&#39;static_feats_categorical&#39;</span><span class="p">]</span>
<span class="n">historical_feats</span> <span class="o">=</span> <span class="n">feature_map</span><span class="p">[</span><span class="s1">&#39;historical_ts_numeric&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">feature_map</span><span class="p">[</span><span class="s1">&#39;historical_ts_categorical&#39;</span><span class="p">]</span>
<span class="n">future_feats</span> <span class="o">=</span> <span class="n">feature_map</span><span class="p">[</span><span class="s1">&#39;future_ts_numeric&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">feature_map</span><span class="p">[</span><span class="s1">&#39;future_ts_categorical&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<p>The description of selection weights can be done either on a data subset level, or on a sample-level. For performing data-set level description, we’ll have to perform some-kind of reduction/aggregation. Hence, we use a configurable list of precentiles, for describing the distribution of selection weights for each variable on each input channel:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[38]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># the precentiles to compute for describing the distribution of the weights</span>
<span class="n">weights_prctile</span> <span class="o">=</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span><span class="mi">50</span><span class="p">,</span><span class="mi">90</span><span class="p">]</span>
</pre></div>
</div>
</div>
<p>On the following we use the functionality implemented under <code class="docutils literal notranslate"><span class="pre">tft_torch.visualize</span></code>, for performing the aggregation and ordering of the attributes, for each input channel separately. For that matter, we supply a mapping specifying the name of output key associated which each set of attributes:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[39]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">mapping</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;Static Weights&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;arr_key&#39;</span><span class="p">:</span> <span class="s1">&#39;static_weights&#39;</span><span class="p">,</span> <span class="s1">&#39;feat_names&#39;</span><span class="p">:</span><span class="n">static_feats</span><span class="p">},</span>
    <span class="s1">&#39;Historical Weights&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;arr_key&#39;</span><span class="p">:</span> <span class="s1">&#39;historical_selection_weights&#39;</span><span class="p">,</span> <span class="s1">&#39;feat_names&#39;</span><span class="p">:</span><span class="n">historical_feats</span><span class="p">},</span>
    <span class="s1">&#39;Future Weights&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;arr_key&#39;</span><span class="p">:</span> <span class="s1">&#39;future_selection_weights&#39;</span><span class="p">,</span> <span class="s1">&#39;feat_names&#39;</span><span class="p">:</span><span class="n">future_feats</span><span class="p">},</span>
<span class="p">}</span>
<span class="n">tft_vis</span><span class="o">.</span><span class="n">display_selection_weights_stats</span><span class="p">(</span><span class="n">outputs_dict</span><span class="o">=</span><span class="n">validation_outputs</span><span class="p">,</span>
                                       <span class="n">prctiles</span><span class="o">=</span><span class="n">weights_prctile</span><span class="p">,</span>
                                       <span class="n">mapping</span><span class="o">=</span><span class="n">mapping</span><span class="p">,</span>
                                       <span class="n">sort_by</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Static Weights
=========
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<style type="text/css">
#T_dadfb_row0_col0, #T_dadfb_row0_col1, #T_dadfb_row1_col2 {
  background-color: #fde725;
  color: #000000;
}
#T_dadfb_row0_col2 {
  background-color: #f1e51d;
  color: #000000;
}
#T_dadfb_row1_col0 {
  background-color: #29af7f;
  color: #f1f1f1;
}
#T_dadfb_row1_col1 {
  background-color: #77d153;
  color: #000000;
}
#T_dadfb_row2_col0 {
  background-color: #5ac864;
  color: #000000;
}
#T_dadfb_row2_col1 {
  background-color: #65cb5e;
  color: #000000;
}
#T_dadfb_row2_col2 {
  background-color: #73d056;
  color: #000000;
}
#T_dadfb_row3_col0 {
  background-color: #2c728e;
  color: #f1f1f1;
}
#T_dadfb_row3_col1 {
  background-color: #29798e;
  color: #f1f1f1;
}
#T_dadfb_row3_col2 {
  background-color: #1e9d89;
  color: #f1f1f1;
}
#T_dadfb_row4_col0 {
  background-color: #375a8c;
  color: #f1f1f1;
}
#T_dadfb_row4_col1 {
  background-color: #38598c;
  color: #f1f1f1;
}
#T_dadfb_row4_col2 {
  background-color: #34608d;
  color: #f1f1f1;
}
#T_dadfb_row5_col0 {
  background-color: #433d84;
  color: #f1f1f1;
}
#T_dadfb_row5_col1 {
  background-color: #3d4e8a;
  color: #f1f1f1;
}
#T_dadfb_row5_col2 {
  background-color: #34618d;
  color: #f1f1f1;
}
#T_dadfb_row6_col0 {
  background-color: #482576;
  color: #f1f1f1;
}
#T_dadfb_row6_col1 {
  background-color: #3e4989;
  color: #f1f1f1;
}
#T_dadfb_row6_col2 {
  background-color: #21a685;
  color: #f1f1f1;
}
#T_dadfb_row7_col0, #T_dadfb_row8_col1, #T_dadfb_row8_col2 {
  background-color: #440154;
  color: #f1f1f1;
}
#T_dadfb_row7_col1 {
  background-color: #471365;
  color: #f1f1f1;
}
#T_dadfb_row7_col2 {
  background-color: #463480;
  color: #f1f1f1;
}
#T_dadfb_row8_col0 {
  background-color: #440256;
  color: #f1f1f1;
}
</style>
<table id="T_dadfb_">
  <thead>
    <tr>
      <th class="blank level0" >&nbsp;</th>
      <th class="col_heading level0 col0" >10</th>
      <th class="col_heading level0 col1" >50</th>
      <th class="col_heading level0 col2" >90</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th id="T_dadfb_level0_row0" class="row_heading level0 row0" >item_class</th>
      <td id="T_dadfb_row0_col0" class="data row0 col0" >0.146418</td>
      <td id="T_dadfb_row0_col1" class="data row0 col1" >0.215050</td>
      <td id="T_dadfb_row0_col2" class="data row0 col2" >0.294322</td>
    </tr>
    <tr>
      <th id="T_dadfb_level0_row1" class="row_heading level0 row1" >store_nbr</th>
      <td id="T_dadfb_row1_col0" class="data row1 col0" >0.097868</td>
      <td id="T_dadfb_row1_col1" class="data row1 col1" >0.175210</td>
      <td id="T_dadfb_row1_col2" class="data row1 col2" >0.300055</td>
    </tr>
    <tr>
      <th id="T_dadfb_level0_row2" class="row_heading level0 row2" >item_nbr</th>
      <td id="T_dadfb_row2_col0" class="data row2 col0" >0.113144</td>
      <td id="T_dadfb_row2_col1" class="data row2 col1" >0.168956</td>
      <td id="T_dadfb_row2_col2" class="data row2 col2" >0.242336</td>
    </tr>
    <tr>
      <th id="T_dadfb_level0_row3" class="row_heading level0 row3" >item_family</th>
      <td id="T_dadfb_row3_col0" class="data row3 col0" >0.064974</td>
      <td id="T_dadfb_row3_col1" class="data row3 col1" >0.099162</td>
      <td id="T_dadfb_row3_col2" class="data row3 col2" >0.178956</td>
    </tr>
    <tr>
      <th id="T_dadfb_level0_row4" class="row_heading level0 row4" >city</th>
      <td id="T_dadfb_row4_col0" class="data row4 col0" >0.052091</td>
      <td id="T_dadfb_row4_col1" class="data row4 col1" >0.074115</td>
      <td id="T_dadfb_row4_col2" class="data row4 col2" >0.111037</td>
    </tr>
    <tr>
      <th id="T_dadfb_level0_row5" class="row_heading level0 row5" >store_type</th>
      <td id="T_dadfb_row5_col0" class="data row5 col0" >0.038503</td>
      <td id="T_dadfb_row5_col1" class="data row5 col1" >0.066235</td>
      <td id="T_dadfb_row5_col2" class="data row5 col2" >0.112813</td>
    </tr>
    <tr>
      <th id="T_dadfb_level0_row6" class="row_heading level0 row6" >state</th>
      <td id="T_dadfb_row6_col0" class="data row6 col0" >0.028883</td>
      <td id="T_dadfb_row6_col1" class="data row6 col1" >0.063422</td>
      <td id="T_dadfb_row6_col2" class="data row6 col2" >0.190131</td>
    </tr>
    <tr>
      <th id="T_dadfb_level0_row7" class="row_heading level0 row7" >perishable</th>
      <td id="T_dadfb_row7_col0" class="data row7 col0" >0.015476</td>
      <td id="T_dadfb_row7_col1" class="data row7 col1" >0.030384</td>
      <td id="T_dadfb_row7_col2" class="data row7 col2" >0.070544</td>
    </tr>
    <tr>
      <th id="T_dadfb_level0_row8" class="row_heading level0 row8" >store_cluster</th>
      <td id="T_dadfb_row8_col0" class="data row8 col0" >0.016169</td>
      <td id="T_dadfb_row8_col1" class="data row8 col1" >0.020616</td>
      <td id="T_dadfb_row8_col2" class="data row8 col2" >0.029639</td>
    </tr>
  </tbody>
</table></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Historical Weights
=========
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<style type="text/css">
#T_64699_row0_col0, #T_64699_row0_col1, #T_64699_row0_col2 {
  background-color: #fde725;
  color: #000000;
}
#T_64699_row1_col0 {
  background-color: #34608d;
  color: #f1f1f1;
}
#T_64699_row1_col1 {
  background-color: #33638d;
  color: #f1f1f1;
}
#T_64699_row1_col2 {
  background-color: #306a8e;
  color: #f1f1f1;
}
#T_64699_row2_col0 {
  background-color: #471063;
  color: #f1f1f1;
}
#T_64699_row2_col1 {
  background-color: #481a6c;
  color: #f1f1f1;
}
#T_64699_row2_col2 {
  background-color: #472a7a;
  color: #f1f1f1;
}
#T_64699_row3_col0 {
  background-color: #481668;
  color: #f1f1f1;
}
#T_64699_row3_col1 {
  background-color: #48186a;
  color: #f1f1f1;
}
#T_64699_row3_col2 {
  background-color: #482173;
  color: #f1f1f1;
}
#T_64699_row4_col0, #T_64699_row6_col1 {
  background-color: #450559;
  color: #f1f1f1;
}
#T_64699_row4_col1 {
  background-color: #470d60;
  color: #f1f1f1;
}
#T_64699_row4_col2 {
  background-color: #482071;
  color: #f1f1f1;
}
#T_64699_row5_col0, #T_64699_row6_col0, #T_64699_row6_col2, #T_64699_row7_col1, #T_64699_row8_col0, #T_64699_row8_col1, #T_64699_row8_col2 {
  background-color: #450457;
  color: #f1f1f1;
}
#T_64699_row5_col1 {
  background-color: #46075a;
  color: #f1f1f1;
}
#T_64699_row5_col2 {
  background-color: #460b5e;
  color: #f1f1f1;
}
#T_64699_row7_col0, #T_64699_row9_col0, #T_64699_row9_col1 {
  background-color: #440256;
  color: #f1f1f1;
}
#T_64699_row7_col2 {
  background-color: #46085c;
  color: #f1f1f1;
}
#T_64699_row9_col2, #T_64699_row10_col0, #T_64699_row10_col1, #T_64699_row10_col2 {
  background-color: #440154;
  color: #f1f1f1;
}
</style>
<table id="T_64699_">
  <thead>
    <tr>
      <th class="blank level0" >&nbsp;</th>
      <th class="col_heading level0 col0" >10</th>
      <th class="col_heading level0 col1" >50</th>
      <th class="col_heading level0 col2" >90</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th id="T_64699_level0_row0" class="row_heading level0 row0" >log_sales</th>
      <td id="T_64699_row0_col0" class="data row0 col0" >0.517847</td>
      <td id="T_64699_row0_col1" class="data row0 col1" >0.575107</td>
      <td id="T_64699_row0_col2" class="data row0 col2" >0.607477</td>
    </tr>
    <tr>
      <th id="T_64699_level0_row1" class="row_heading level0 row1" >day_of_week</th>
      <td id="T_64699_row1_col0" class="data row1 col0" >0.161197</td>
      <td id="T_64699_row1_col1" class="data row1 col1" >0.188109</td>
      <td id="T_64699_row1_col2" class="data row1 col2" >0.217286</td>
    </tr>
    <tr>
      <th id="T_64699_level0_row2" class="row_heading level0 row2" >day_of_month</th>
      <td id="T_64699_row2_col0" class="data row2 col0" >0.029436</td>
      <td id="T_64699_row2_col1" class="data row2 col1" >0.049185</td>
      <td id="T_64699_row2_col2" class="data row2 col2" >0.084286</td>
    </tr>
    <tr>
      <th id="T_64699_level0_row3" class="row_heading level0 row3" >onpromotion</th>
      <td id="T_64699_row3_col0" class="data row3 col0" >0.036496</td>
      <td id="T_64699_row3_col1" class="data row3 col1" >0.046337</td>
      <td id="T_64699_row3_col2" class="data row3 col2" >0.068408</td>
    </tr>
    <tr>
      <th id="T_64699_level0_row4" class="row_heading level0 row4" >month</th>
      <td id="T_64699_row4_col0" class="data row4 col0" >0.013957</td>
      <td id="T_64699_row4_col1" class="data row4 col1" >0.028247</td>
      <td id="T_64699_row4_col2" class="data row4 col2" >0.065884</td>
    </tr>
    <tr>
      <th id="T_64699_level0_row5" class="row_heading level0 row5" >regional_holiday</th>
      <td id="T_64699_row5_col0" class="data row5 col0" >0.013225</td>
      <td id="T_64699_row5_col1" class="data row5 col1" >0.020719</td>
      <td id="T_64699_row5_col2" class="data row5 col2" >0.032937</td>
    </tr>
    <tr>
      <th id="T_64699_level0_row6" class="row_heading level0 row6" >local_holiday</th>
      <td id="T_64699_row6_col0" class="data row6 col0" >0.013515</td>
      <td id="T_64699_row6_col1" class="data row6 col1" >0.017147</td>
      <td id="T_64699_row6_col2" class="data row6 col2" >0.020924</td>
    </tr>
    <tr>
      <th id="T_64699_level0_row7" class="row_heading level0 row7" >oil_price</th>
      <td id="T_64699_row7_col0" class="data row7 col0" >0.010190</td>
      <td id="T_64699_row7_col1" class="data row7 col1" >0.016742</td>
      <td id="T_64699_row7_col2" class="data row7 col2" >0.027128</td>
    </tr>
    <tr>
      <th id="T_64699_level0_row8" class="row_heading level0 row8" >transactions</th>
      <td id="T_64699_row8_col0" class="data row8 col0" >0.011805</td>
      <td id="T_64699_row8_col1" class="data row8 col1" >0.015978</td>
      <td id="T_64699_row8_col2" class="data row8 col2" >0.020759</td>
    </tr>
    <tr>
      <th id="T_64699_level0_row9" class="row_heading level0 row9" >open</th>
      <td id="T_64699_row9_col0" class="data row9 col0" >0.011150</td>
      <td id="T_64699_row9_col1" class="data row9 col1" >0.013105</td>
      <td id="T_64699_row9_col2" class="data row9 col2" >0.015752</td>
    </tr>
    <tr>
      <th id="T_64699_level0_row10" class="row_heading level0 row10" >national_holiday</th>
      <td id="T_64699_row10_col0" class="data row10 col0" >0.007565</td>
      <td id="T_64699_row10_col1" class="data row10 col1" >0.010140</td>
      <td id="T_64699_row10_col2" class="data row10 col2" >0.014467</td>
    </tr>
  </tbody>
</table></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Future Weights
=========
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<style type="text/css">
#T_d3dd3_row0_col0, #T_d3dd3_row0_col1, #T_d3dd3_row0_col2 {
  background-color: #fde725;
  color: #000000;
}
#T_d3dd3_row1_col0 {
  background-color: #1fa287;
  color: #f1f1f1;
}
#T_d3dd3_row1_col1 {
  background-color: #1f9e89;
  color: #f1f1f1;
}
#T_d3dd3_row1_col2 {
  background-color: #29af7f;
  color: #f1f1f1;
}
#T_d3dd3_row2_col0 {
  background-color: #3e4a89;
  color: #f1f1f1;
}
#T_d3dd3_row2_col1 {
  background-color: #365d8d;
  color: #f1f1f1;
}
#T_d3dd3_row2_col2 {
  background-color: #24878e;
  color: #f1f1f1;
}
#T_d3dd3_row3_col0 {
  background-color: #3a548c;
  color: #f1f1f1;
}
#T_d3dd3_row3_col1 {
  background-color: #3c4f8a;
  color: #f1f1f1;
}
#T_d3dd3_row3_col2, #T_d3dd3_row5_col2 {
  background-color: #32648e;
  color: #f1f1f1;
}
#T_d3dd3_row4_col0 {
  background-color: #433d84;
  color: #f1f1f1;
}
#T_d3dd3_row4_col1 {
  background-color: #3e4c8a;
  color: #f1f1f1;
}
#T_d3dd3_row4_col2 {
  background-color: #3b528b;
  color: #f1f1f1;
}
#T_d3dd3_row5_col0 {
  background-color: #472e7c;
  color: #f1f1f1;
}
#T_d3dd3_row5_col1 {
  background-color: #414287;
  color: #f1f1f1;
}
#T_d3dd3_row6_col0 {
  background-color: #48186a;
  color: #f1f1f1;
}
#T_d3dd3_row6_col1 {
  background-color: #472d7b;
  color: #f1f1f1;
}
#T_d3dd3_row6_col2 {
  background-color: #3c508b;
  color: #f1f1f1;
}
#T_d3dd3_row7_col0, #T_d3dd3_row7_col1, #T_d3dd3_row7_col2 {
  background-color: #440154;
  color: #f1f1f1;
}
</style>
<table id="T_d3dd3_">
  <thead>
    <tr>
      <th class="blank level0" >&nbsp;</th>
      <th class="col_heading level0 col0" >10</th>
      <th class="col_heading level0 col1" >50</th>
      <th class="col_heading level0 col2" >90</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th id="T_d3dd3_level0_row0" class="row_heading level0 row0" >day_of_week</th>
      <td id="T_d3dd3_row0_col0" class="data row0 col0" >0.221024</td>
      <td id="T_d3dd3_row0_col1" class="data row0 col1" >0.331123</td>
      <td id="T_d3dd3_row0_col2" class="data row0 col2" >0.443231</td>
    </tr>
    <tr>
      <th id="T_d3dd3_level0_row1" class="row_heading level0 row1" >local_holiday</th>
      <td id="T_d3dd3_row1_col0" class="data row1 col0" >0.131050</td>
      <td id="T_d3dd3_row1_col1" class="data row1 col1" >0.189638</td>
      <td id="T_d3dd3_row1_col2" class="data row1 col2" >0.284440</td>
    </tr>
    <tr>
      <th id="T_d3dd3_level0_row2" class="row_heading level0 row2" >day_of_month</th>
      <td id="T_d3dd3_row2_col0" class="data row2 col0" >0.055802</td>
      <td id="T_d3dd3_row2_col1" class="data row2 col1" >0.103773</td>
      <td id="T_d3dd3_row2_col2" class="data row2 col2" >0.213172</td>
    </tr>
    <tr>
      <th id="T_d3dd3_level0_row3" class="row_heading level0 row3" >onpromotion</th>
      <td id="T_d3dd3_row3_col0" class="data row3 col0" >0.063258</td>
      <td id="T_d3dd3_row3_col1" class="data row3 col1" >0.087982</td>
      <td id="T_d3dd3_row3_col2" class="data row3 col2" >0.151555</td>
    </tr>
    <tr>
      <th id="T_d3dd3_level0_row4" class="row_heading level0 row4" >month</th>
      <td id="T_d3dd3_row4_col0" class="data row4 col0" >0.045902</td>
      <td id="T_d3dd3_row4_col1" class="data row4 col1" >0.083580</td>
      <td id="T_d3dd3_row4_col2" class="data row4 col2" >0.122220</td>
    </tr>
    <tr>
      <th id="T_d3dd3_level0_row5" class="row_heading level0 row5" >national_holiday</th>
      <td id="T_d3dd3_row5_col0" class="data row5 col0" >0.035846</td>
      <td id="T_d3dd3_row5_col1" class="data row5 col1" >0.074236</td>
      <td id="T_d3dd3_row5_col2" class="data row5 col2" >0.151380</td>
    </tr>
    <tr>
      <th id="T_d3dd3_level0_row6" class="row_heading level0 row6" >regional_holiday</th>
      <td id="T_d3dd3_row6_col0" class="data row6 col0" >0.022075</td>
      <td id="T_d3dd3_row6_col1" class="data row6 col1" >0.051017</td>
      <td id="T_d3dd3_row6_col2" class="data row6 col2" >0.119778</td>
    </tr>
    <tr>
      <th id="T_d3dd3_level0_row7" class="row_heading level0 row7" >open</th>
      <td id="T_d3dd3_row7_col0" class="data row7 col0" >0.008381</td>
      <td id="T_d3dd3_row7_col1" class="data row7 col1" >0.010621</td>
      <td id="T_d3dd3_row7_col2" class="data row7 col2" >0.014565</td>
    </tr>
  </tbody>
</table></div>
</div>
<p>The tables above display the specified percentiles of the weights distribution for each feature, on each input channel. The color of each cell is highlighted according to the corresponding value (brighter color implies higher value). In addition, every table is sorted (in descending order) according to configured percentile. Note that for the temporal inputs (historical_ts, future_ts), the time-series of weights gets “flattened”, so that we can aggregate along time-steps and samples likewise.
Generally, the selection weights for the temporal data, are generated for each time-step separately. Here, we look at all the time-steps altogether, but this can be another aspect to examine.</p>
<p>Some interesting findings that are easily seen using these tables:</p>
<ul class="simple">
<li><p>For the static weights, the attributes that seem to have the highest weights (thus considered more important), are the ones associated with the identity of the instance - <em>store_nbr</em> , <em>item_class</em> , <em>item_nbr</em> .</p></li>
<li><p>The most important variable, in terms of selection weight, among the historical features, is the variable we aim at predicting into the future - <em>log_sales</em> - which makes sense, of course.</p></li>
<li><p>Among the known (futuristic) inputs, we see that the knowledge about the next weekdays and the upcoming promotions is of high importance to the model.</p></li>
</ul>
<p>As noted earlier, we can examine the selection weights from the point of view of an invdividual sample. Using the functionality implemented on <code class="docutils literal notranslate"><span class="pre">tft_torch.visualize</span></code> we call <code class="docutils literal notranslate"><span class="pre">display_sample_wise_selection_stats()</span></code> function, each time for another input channel, specying the observation index for which we want to observe the selection weights distribution.</p>
<ul class="simple">
<li><p>For each of the input channel we get an ordered barplot of the selection weights. Note that for the selection weights of the temporal attributes, there’s a step of flattening and averaging. For the barplot we also allow specifying the <code class="docutils literal notranslate"><span class="pre">top_n</span></code> argument, for keeping only the <code class="docutils literal notranslate"><span class="pre">top_n</span></code> ranked attributes on this plot. Note that the selection weights on the barplot, for the static variables (which do not require flattening and aggregation) sum up to 1.0 (unless truncated using <code class="docutils literal notranslate"><span class="pre">top_n</span></code>).</p></li>
<li><p>For the selection weights of the temporal input channel, the same function will also provide some kind of “<em>spectrogram</em>” indicating the distribution of selection weights along time. This visualization can be configured to rank the attributes separately on each time-step, by setting <code class="docutils literal notranslate"><span class="pre">rank_stepwise=True</span></code>.</p></li>
</ul>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[47]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># static attributes</span>
<span class="n">tft_vis</span><span class="o">.</span><span class="n">display_sample_wise_selection_stats</span><span class="p">(</span><span class="n">weights_arr</span><span class="o">=</span><span class="n">validation_outputs</span><span class="p">[</span><span class="s1">&#39;static_weights&#39;</span><span class="p">],</span>
                                           <span class="n">observation_index</span><span class="o">=</span><span class="n">chosen_idx</span><span class="p">,</span>
                                           <span class="n">feature_names</span><span class="o">=</span><span class="n">static_feats</span><span class="p">,</span>
                                           <span class="n">top_n</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
                                           <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Static Features&#39;</span><span class="p">)</span>

<span class="c1"># historical temporal attributes</span>
<span class="n">tft_vis</span><span class="o">.</span><span class="n">display_sample_wise_selection_stats</span><span class="p">(</span><span class="n">weights_arr</span><span class="o">=</span><span class="n">validation_outputs</span><span class="p">[</span><span class="s1">&#39;historical_selection_weights&#39;</span><span class="p">],</span>
                                           <span class="n">observation_index</span><span class="o">=</span><span class="n">chosen_idx</span><span class="p">,</span>
                                           <span class="n">feature_names</span><span class="o">=</span><span class="n">historical_feats</span><span class="p">,</span>
                                           <span class="n">top_n</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
                                           <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Historical Features&#39;</span><span class="p">,</span>
                                           <span class="n">rank_stepwise</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># futuristic (known) temporal attributes</span>
<span class="n">tft_vis</span><span class="o">.</span><span class="n">display_sample_wise_selection_stats</span><span class="p">(</span><span class="n">weights_arr</span><span class="o">=</span><span class="n">validation_outputs</span><span class="p">[</span><span class="s1">&#39;future_selection_weights&#39;</span><span class="p">],</span>
                                           <span class="n">observation_index</span><span class="o">=</span><span class="n">chosen_idx</span><span class="p">,</span>
                                           <span class="n">feature_names</span><span class="o">=</span><span class="n">future_feats</span><span class="p">,</span>
                                           <span class="n">top_n</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
                                           <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Future Features&#39;</span><span class="p">,</span>
                                           <span class="n">historical</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                           <span class="n">rank_stepwise</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorials_TrainingExample_85_0.png" src="../_images/tutorials_TrainingExample_85_0.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorials_TrainingExample_85_1.png" src="../_images/tutorials_TrainingExample_85_1.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorials_TrainingExample_85_2.png" src="../_images/tutorials_TrainingExample_85_2.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorials_TrainingExample_85_3.png" src="../_images/tutorials_TrainingExample_85_3.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorials_TrainingExample_85_4.png" src="../_images/tutorials_TrainingExample_85_4.png" />
</div>
</div>
<p>Looking at the barplots above, we can see that although in some cases the ordering of selection weights observed for the individual sample does go hand-in-hand with the ordering observed in the aggregative form (on the dataset level), this might not always be the case. Having the ability to observe selection weights on a single sample level enables us to investigate specific samples and understand which variables of this specific sample affected the model the most, and led to un/successful
prediction.</p>
<p>Now, to the additional visualization: as explained above, the distribution of selection weights is different for each time-step. The image-like visualization is used to describe this distribution along time; higher selection weights are depicted by a brighter color. When <code class="docutils literal notranslate"><span class="pre">rank_stepwise</span></code> is set to <code class="docutils literal notranslate"><span class="pre">False</span></code>, the visualization is using a uniform scale of selection weights along the entire time axis. Therefore, on time-steps where the distribution of selection weights has higher entropy (less
concentrated with a narrow set of few features), the selected input variables seem (according to chart) “less important”. In order to overcome this, one can set <code class="docutils literal notranslate"><span class="pre">rank_stepwise</span></code> to <code class="docutils literal notranslate"><span class="pre">True</span></code>, and the chart will display the same information, but the cells will be colored according to the order of the features (or according to their resepctive selection weight, to be precise) on each time step separately.</p>
</div>
<div class="section" id="Attention-Scores">
<h3>Attention Scores<a class="headerlink" href="#Attention-Scores" title="Permalink to this headline">¶</a></h3>
<p>The temporal fusion transformer model has an internal attention mechanism for weighting the information coming from the sequential data (whether it is the historical sequence or the future sequential data). Part of the model outputs, for each observation, are the attention scores of the model. We can use these scores to try and infer which preceding time-steps affected the output of the model the most. Recall that due to masking, each Future horizon can “assign” attention only to steps that came
before. On this part, we examine the scores both globally (for the entire validation set) and individually (on a single-sample level).</p>
<p>As in the case of aggregating the selection weights, for supply a quantitative description of the scores distribution we use percentiles.</p>
</div>
</div>
<div class="section" id="One-step-ahead">
<h2>One step ahead<a class="headerlink" href="#One-step-ahead" title="Permalink to this headline">¶</a></h2>
<p>The attention scores are horizon-specific, i.e. every future horizon maintains a different set of attention scores for the corresponding observable time-steps. First, we’ll examine the attention scores for a one-day horizon (t+1) into the future.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[48]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">tft_vis</span><span class="o">.</span><span class="n">display_attention_scores</span><span class="p">(</span><span class="n">attention_scores</span><span class="o">=</span><span class="n">validation_outputs</span><span class="p">[</span><span class="s1">&#39;attention_scores&#39;</span><span class="p">],</span>
                                <span class="n">horizons</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                <span class="n">prctiles</span><span class="o">=</span><span class="p">[</span><span class="mi">10</span><span class="p">,</span><span class="mi">50</span><span class="p">,</span><span class="mi">90</span><span class="p">],</span>
                                <span class="n">unit</span><span class="o">=</span><span class="s1">&#39;Days&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorials_TrainingExample_91_0.png" src="../_images/tutorials_TrainingExample_91_0.png" />
</div>
</div>
<p>The dashed line stands for the separation between the historical time-steps, and the futuristic time-steps. For each step we compute the relevant percentiles of the attention scores. The attention scores for the further time-steps are zeroed out by design, using the internal masking mechanism within the TFT model. We can see clearly the 7 days cycle among the attention scores, and the general trend according to which the most recent cycles (the ones that are closer to the <em>separation</em> line, are
more dominant than previous, gradually forgotten, cycles.</p>
</div>
<div class="section" id="Multihorizon-Attention">
<h2>Multihorizon Attention<a class="headerlink" href="#Multihorizon-Attention" title="Permalink to this headline">¶</a></h2>
<p>As noted above, each future horizon step has its own set of attention scores. Using the same function we can describe the attention scores distribution for multiple horizons at once.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[49]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">tft_vis</span><span class="o">.</span><span class="n">display_attention_scores</span><span class="p">(</span><span class="n">attention_scores</span><span class="o">=</span><span class="n">validation_outputs</span><span class="p">[</span><span class="s1">&#39;attention_scores&#39;</span><span class="p">],</span>
                                <span class="n">horizons</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">5</span><span class="p">],</span>
                                <span class="n">prctiles</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
                                <span class="n">unit</span><span class="o">=</span><span class="s1">&#39;Days&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorials_TrainingExample_94_0.png" src="../_images/tutorials_TrainingExample_94_0.png" />
</div>
</div>
<p>We can see that the attention scores for the historical time-steps have quite similiar <em>characteristics</em> among the different horizons. They all are decaying towards the past, they all have weekly cycles, but, their weekly cycles are offset due to the difference in weekdays.</p>
<p>The attention scores can also be explored in the single-sample level using <code class="docutils literal notranslate"><span class="pre">display_sample_wise_attention_scores()</span></code> function. The following chart presents the scores associated with each output horizon (see legend). When we compare scorings of different horizons, we can see that the attention scores signal is somewhat correlated between two differnet horizon.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[50]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">tft_vis</span><span class="o">.</span><span class="n">display_sample_wise_attention_scores</span><span class="p">(</span><span class="n">attention_scores</span><span class="o">=</span><span class="n">validation_outputs</span><span class="p">[</span><span class="s1">&#39;attention_scores&#39;</span><span class="p">],</span>
                                            <span class="n">observation_index</span><span class="o">=</span><span class="n">chosen_idx</span><span class="p">,</span>
                                            <span class="n">horizons</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">10</span><span class="p">],</span>
                                            <span class="n">unit</span><span class="o">=</span><span class="s1">&#39;Days&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorials_TrainingExample_97_0.png" src="../_images/tutorials_TrainingExample_97_0.png" />
</div>
</div>
<p>And that’s it! Enjoy using <code class="docutils literal notranslate"><span class="pre">tft_torch</span></code></p>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="../modules.html" class="btn btn-neutral float-right" title="tft-torch Modules" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="DataGenerationExample.html" class="btn btn-neutral float-left" title="Favorita Dataset Creation Example" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, Dvir Ben Or.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>