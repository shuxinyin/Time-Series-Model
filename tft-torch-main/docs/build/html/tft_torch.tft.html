

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>tft_torch.tft module &mdash; tft-torch 0.0.1 documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="tft_torch.loss module" href="tft_torch.loss.html" />
    <link rel="prev" title="tft-torch Modules" href="modules.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> tft-torch
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="introduction.html">tft-torch</a></li>
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorials.html">Tutorials</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="modules.html">tft-torch Modules</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">tft_torch.tft module</a></li>
<li class="toctree-l2"><a class="reference internal" href="tft_torch.loss.html">tft_torch.loss module</a></li>
<li class="toctree-l2"><a class="reference internal" href="tft_torch.base_blocks.html">tft_torch.base_blocks module</a></li>
<li class="toctree-l2"><a class="reference internal" href="tft_torch.visualize.html">tft_torch.visualize module</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="help.html">Help</a></li>
<li class="toctree-l1"><a class="reference internal" href="authors.html">Authors</a></li>
<li class="toctree-l1"><a class="reference internal" href="license.html">License</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">tft-torch</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="modules.html">tft-torch Modules</a> &raquo;</li>
        
      <li>tft_torch.tft module</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/tft_torch.tft.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="tft-torch-tft-module">
<h1>tft_torch.tft module<a class="headerlink" href="#tft-torch-tft-module" title="Permalink to this headline">¶</a></h1>
<p>This module contains the primary model implemented in this project.</p>
<dl class="py class">
<dt class="sig sig-object py" id="tft_torch.tft.TemporalFusionTransformer">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">tft_torch.tft.</span></span><span class="sig-name descname"><span class="pre">TemporalFusionTransformer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">omegaconf.dictconfig.DictConfig</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tft_torch.tft.TemporalFusionTransformer" title="Permalink to this definition">¶</a></dt>
<dd><p>This class implements the Temporal Fusion Transformer model described in the paper
<a class="reference external" href="https://arxiv.org/abs/1912.09363">Temporal Fusion Transformers for Interpretable Multi-horizon Time Series Forecasting</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>config</strong> (<em>DictConfig</em>) – A mapping describing both the expected structure of the input of the model, and the architectural specification
of the model.
This mapping should include a key named <code class="docutils literal notranslate"><span class="pre">data_props</span></code> in which the dimensions and cardinalities (where the
inputs are categorical) are specified. Moreover, the configuration mapping should contain a key named <code class="docutils literal notranslate"><span class="pre">model</span></code>,
specifying <code class="docutils literal notranslate"><span class="pre">attention_heads</span></code> , <code class="docutils literal notranslate"><span class="pre">dropout</span></code> , <code class="docutils literal notranslate"><span class="pre">lstm_layers</span></code> , <code class="docutils literal notranslate"><span class="pre">output_quantiles</span></code> and <code class="docutils literal notranslate"><span class="pre">state_size</span></code> ,
which are required for creating the model.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="tft_torch.tft.InputChannelEmbedding">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">tft_torch.tft.</span></span><span class="sig-name descname"><span class="pre">InputChannelEmbedding</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state_size</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_numeric</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_categorical</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">categorical_cardinalities</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">time_distribute</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tft_torch.tft.InputChannelEmbedding" title="Permalink to this definition">¶</a></dt>
<dd><p>A module to handle the transformation/embedding of an input channel composed of numeric tensors and categorical
tensors.
It holds a NumericInputTransformation module for handling the embedding of the numeric inputs,
and a CategoricalInputTransformation module for handling the embedding of the categorical inputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>state_size</strong> (<em>int</em>) – The state size of the model, which determines the embedding dimension/width of each input variable.</p></li>
<li><p><strong>num_numeric</strong> (<em>int</em>) – The quantity of numeric input variables associated with the input channel.</p></li>
<li><p><strong>num_categorical</strong> (<em>int</em>) – The quantity of categorical input variables associated with the input channel.</p></li>
<li><p><strong>categorical_cardinalities</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – The quantity of categories associated with each of the categorical input variables.</p></li>
<li><p><strong>time_distribute</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) – A boolean indicating whether to wrap the composing transformations using the <code class="docutils literal notranslate"><span class="pre">TimeDistributed</span></code> module.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="tft_torch.tft.NumericInputTransformation">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">tft_torch.tft.</span></span><span class="sig-name descname"><span class="pre">NumericInputTransformation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_inputs</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">state_size</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tft_torch.tft.NumericInputTransformation" title="Permalink to this definition">¶</a></dt>
<dd><p>A module for transforming/embeddings the set of numeric input variables from a single input channel.
Each input variable will be projected using a dedicated linear layer to a vector with width state_size.
The result of applying this module is a list, with length num_inputs, that contains the embedding of each input
variable for all the observations and time steps.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_inputs</strong> (<em>int</em>) – The quantity of numeric input variables associated with this module.</p></li>
<li><p><strong>state_size</strong> (<em>int</em>) – The state size of the model, which determines the embedding dimension/width.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="tft_torch.tft.CategoricalInputTransformation">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">tft_torch.tft.</span></span><span class="sig-name descname"><span class="pre">CategoricalInputTransformation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_inputs</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">state_size</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cardinalities</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tft_torch.tft.CategoricalInputTransformation" title="Permalink to this definition">¶</a></dt>
<dd><p>A module for transforming/embeddings the set of categorical input variables from a single input channel.
Each input variable will be projected using a dedicated embedding layer to a vector with width state_size.
The result of applying this module is a list, with length num_inputs, that contains the embedding of each input
variable for all the observations and time steps.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_inputs</strong> (<em>int</em>) – The quantity of categorical input variables associated with this module.</p></li>
<li><p><strong>state_size</strong> (<em>int</em>) – The state size of the model, which determines the embedding dimension/width.</p></li>
<li><p><strong>cardinalities</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – The quantity of categories associated with each of the input variables.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="tft_torch.tft.VariableSelectionNetwork">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">tft_torch.tft.</span></span><span class="sig-name descname"><span class="pre">VariableSelectionNetwork</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_dim</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_inputs</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_dim</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context_dim</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_first</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tft_torch.tft.VariableSelectionNetwork" title="Permalink to this definition">¶</a></dt>
<dd><p>This module is designed to handle the fact that the relevant and specific contribution of each input variable
to the  output is typically unknown. This module enables instance-wise variable selection, and is applied to
both the static covariates and time-dependent covariates.</p>
<p>Beyond providing insights into which variables are the most significant oones for the prediction problem,
variable selection also allows the model to remove any unnecessary noisy inputs which could negatively impact
performance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_dim</strong> (<em>int</em>) – The attribute/embedding dimension of the input, associated with the <code class="docutils literal notranslate"><span class="pre">state_size</span></code> of th model.</p></li>
<li><p><strong>num_inputs</strong> (<em>int</em>) – The quantity of input variables, including both numeric and categorical inputs for the relevant channel.</p></li>
<li><p><strong>hidden_dim</strong> (<em>int</em>) – The embedding width of the output.</p></li>
<li><p><strong>dropout</strong> (<em>float</em>) – The dropout rate associated with <code class="docutils literal notranslate"><span class="pre">GatedResidualNetwork</span></code> objects composing this object.</p></li>
<li><p><strong>context_dim</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – The embedding width of the context signal expected to be fed as an auxiliary input to this component.</p></li>
<li><p><strong>batch_first</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) – A boolean indicating whether the batch dimension is expected to be the first dimension of the input or not.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="tft_torch.tft.GatedLinearUnit">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">tft_torch.tft.</span></span><span class="sig-name descname"><span class="pre">GatedLinearUnit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_dim</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tft_torch.tft.GatedLinearUnit" title="Permalink to this definition">¶</a></dt>
<dd><p>This module is also known as  <strong>GLU</strong> - Formulated in:
<a class="reference external" href="https://arxiv.org/abs/1612.08083">Dauphin, Yann N., et al. “Language modeling with gated convolutional networks.”
International conference on machine learning. PMLR, 2017</a>.</p>
<p>The output of the layer is a linear projection (X * W + b) modulated by the gates <strong>sigmoid</strong> (X * V + c).
These gates multiply each element of the matrix X * W + b and control the information passed on in the hierarchy.
This unit is a simplified gating mechanism for non-deterministic gates that reduce the vanishing gradient problem,
by having linear units coupled to the gates. This retains the non-linear capabilities of the layer while allowing
the gradient to propagate through the linear unit without scaling.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>input_dim</strong> (<em>int</em>) – The embedding size of the input.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="tft_torch.tft.GatedResidualNetwork">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">tft_torch.tft.</span></span><span class="sig-name descname"><span class="pre">GatedResidualNetwork</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_dim</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_dim</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_dim</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0.05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context_dim</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_first</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tft_torch.tft.GatedResidualNetwork" title="Permalink to this definition">¶</a></dt>
<dd><p>This module, known as <strong>GRN</strong>, takes in a primary input (x) and an optional context vector (c).
It uses a <code class="docutils literal notranslate"><span class="pre">GatedLinearUnit</span></code> for controlling the extent to which the module will contribute to the original input
(x), potentially skipping over the layer entirely as the GLU outputs could be all close to zero, by that suppressing
the non-linear contribution.
In cases where no context vector is used, the GRN simply treats the context input as zero.
During training, dropout is applied before the gating layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_dim</strong> (<em>int</em>) – The embedding width/dimension of the input.</p></li>
<li><p><strong>hidden_dim</strong> (<em>int</em>) – The intermediate embedding width.</p></li>
<li><p><strong>output_dim</strong> (<em>int</em>) – The embedding width of the output tensors.</p></li>
<li><p><strong>dropout</strong> (<em>Optional</em><em>[</em><em>float</em><em>]</em>) – The dropout rate associated with the component.</p></li>
<li><p><strong>context_dim</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – The embedding width of the context signal expected to be fed as an auxiliary input to this component.</p></li>
<li><p><strong>batch_first</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) – A boolean indicating whether the batch dimension is expected to be the first dimension of the input or not.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="tft_torch.tft.GateAddNorm">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">tft_torch.tft.</span></span><span class="sig-name descname"><span class="pre">GateAddNorm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_dim</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tft_torch.tft.GateAddNorm" title="Permalink to this definition">¶</a></dt>
<dd><p>This module encapsulates an operation performed multiple times across the TemporalFusionTransformer model.
The composite operation includes:
a. A <em>Dropout</em> layer.
b. Gating using a <code class="docutils literal notranslate"><span class="pre">GatedLinearUnit</span></code>.
c. A residual connection to an “earlier” signal from the forward pass of the parent model.
d. Layer normalization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_dim</strong> (<em>int</em>) – The dimension associated with the expected input of this module.</p></li>
<li><p><strong>dropout</strong> (<em>Optional</em><em>[</em><em>float</em><em>]</em>) – The dropout rate associated with the component.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="tft_torch.tft.InterpretableMultiHeadAttention">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">tft_torch.tft.</span></span><span class="sig-name descname"><span class="pre">InterpretableMultiHeadAttention</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">embed_dim</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_heads</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tft_torch.tft.InterpretableMultiHeadAttention" title="Permalink to this definition">¶</a></dt>
<dd><p>The mechanism implemented in this module is used to learn long-term relationships across different time-steps.
It is a modified version of multi-head attention, for enhancing explainability. On this modification,
as opposed to traditional versions of multi-head attention, the “values” signal is shared for all the heads -
and additive aggregation is employed across all the heads.
According to the paper, each head can learn different temporal patterns, while attending to a common set of
input features which can be interpreted as  a simple ensemble over attention weights into a combined matrix, which,
compared to the original multi-head attention matrix, yields an increased representation capacity in an efficient
way.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>embed_dim</strong> (<em>int</em>) – The dimensions associated with the <code class="docutils literal notranslate"><span class="pre">state_size</span></code> of th model, corresponding to the input as well as the output.</p></li>
<li><p><strong>num_heads</strong> (<em>int</em>) – The number of attention heads composing the Multi-head attention component.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="tft_torch.loss.html" class="btn btn-neutral float-right" title="tft_torch.loss module" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="modules.html" class="btn btn-neutral float-left" title="tft-torch Modules" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, Dvir Ben Or.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>